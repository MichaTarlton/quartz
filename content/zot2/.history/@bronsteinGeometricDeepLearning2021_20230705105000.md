---

aliases: ["NA et al. (2021)",]
aliases:
  - M.M. Bronstein, J. Bruna, T. Cohen, P. Veliƒçkoviƒá (2021)
type: citation
status: open
project: NA
priority: P5

creationtag: <% tp.file.creation_date() %>

people: ["M.M. Bronstein", "J. Bruna", "T. Cohen", "P. Veliƒçkoviƒá"]
creationtag: 2022-10-06 14:23
people:
  - M.M. Bronstein
  - J. Bruna
  - T. Cohen
  - P. Veliƒçkoviƒá
title: "Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges"
dateadd: 2022-10-06T12:20:59Z
citetype: Preprint
year: 2021
journal: NA

URL: "NA"
URL: NA
DOI: 10.48550/arXiv.2104.13478
citekey: bronsteinGeometricDeepLearning2021
collection: NA

tags: [Computer Science - Artificial Intelligence, Computer Science - Computational Geometry, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning]
tags:
  - Computer Science - Artificial Intelligence
  - Computer Science - Computational Geometry
  - Computer Science - Computer Vision and Pattern Recognition
  - Computer Science - Machine Learning
  - Statistics - Machine Learning
file: ""
---

# Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges
Read:: 
- [ ] Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges M.M. Bronstein, J. Bruna, T. Cohen, P. Veliƒçkoviƒá 2021 üõ´ NA #reading #citation
Print::  ‚ùå
Zotero Link:: NA
PDF:: NA
Files:: [arXiv.org Snapshot](file:////home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/YFGDAL53/2104.html); [Bronstein et al_2021_Geometric Deep Learning.pdf](file:////home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/UCXEX5LG/Bronstein%20et%20al_2021_Geometric%20Deep%20Learning.pdf)

Files:: [arXiv.org Snapshot](file:///C:%5CUsers%5Cmichaelt%5CInsync%5Cm@tarlton.info%5CGoogle%20Drive%5C06.%20Zotero%5Cstorage%5CYFGDAL53%5C2104.html); [Bronstein et al_2021_Geometric Deep Learning.pdf](file:///C:%5CUsers%5Cmichaelt%5CInsync%5Cm@tarlton.info%5CGoogle%20Drive%5C06.%20Zotero%5Cstorage_new%5CarXiv_2021%5CBronstein%20et%20al_2021_Geometric%20Deep%20Learning.pdf)
Reading Note:: [[M.M. Bronstein, J. Bruna, T. Cohen, P. Veliƒçkoviƒá (2021)]]
Web Rip:: 

```dataview
TABLE without id
file.link as "Related Files",
title as "Title",
type as "type"
FROM "" AND -"ZZ. planning"
WHERE citekey = "bronsteinGeometricDeepLearning2021" 
SORT file.cday DESC

> [!Excerpt] Abstract
```

# Abstract
The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.

# Quick Reference


# Top Comments

Let's say grey is for overall comments


# Topics


# Further Reading 
 

----
# Notes
Comment: 156 pages. Work in progress -- comments welcome!

----
# Extracted Annotations and Comments


# Figures