---
aliases:
  - N. Hardy, D. Buonomano 2018
type: citation
status: open
people:
  - N. Hardy
  - D. Buonomano
title: Encoding Time in Feedforward Trajectories of a Recurrent Neural Network Model
dateadd: 2022-06-08T13:50:02Z
citetype: journalArticle
year: 2018
journal: Neural Computation
URL: NA
DOI: 10.1162/neco_a_01041
citekey: hardyEncodingTimeFeedforward2018
collection: From Paton 2018
tags:
  - NA
file: ""
---

# Encoding Time in Feedforward Trajectories of a Recurrent Neural Network Model
Read:: 
Project:: []
Print::  ❌
- [ ] print 
Zotero Link:: NA
PDF:: NA
Files:: [Hardy_Buonomano_2018_Encoding Time in Feedforward Trajectories of a Recurrent Neural Network Model.pdf](file:///home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/JGL3THYL/Hardy_Buonomano_2018_Encoding%20Time%20in%20Feedforward%20Trajectories%20of%20a%20Recurrent%20Neural%20Network%20Model.pdf); [Semantic Scholar Link](file://)
Reading Note:: [[N. Hardy, D. Buonomano 2018]]

# Abstract
It is established for the first time that the same RNN can generate multiple functionally feedforward patterns of activity as a result of dynamic shifts in the E/I balance imposed by the connectome of the RNN. Brain activity evolves through time, creating trajectories of activity that underlie sensorimotor processing, behavior, and learning and memory. Therefore, understanding the temporal nature of neural dynamics is essential to understanding brain function and behavior. In vivo studies have demonstrated that sequential transient activation of neurons can encode time. However, it remains unclear whether these patterns emerge from feedforward network architectures or from recurrent networks and, furthermore, what role network structure plays in timing. We address these issues using a recurrent neural network (RNN) model with distinct populations of excitatory and inhibitory units. Consistent with experimental data, a single RNN could autonomously produce multiple functionally feedforward trajectories, thus potentially encoding multiple timed motor patterns lasting up to several seconds. Importantly, the model accounted for Weber's law, a hallmark of timing behavior. Analysis of network connectivity revealed that efficiency—a measure of network interconnectedness—decreased as the number of stored trajectories increased. Additionally, the balance of excitation (E) and inhibition (I) shifted toward excitation during each unit's activation time, generating the prediction that observed sequential activity relies on dynamic control of the E/I balance. Our results establish for the first time that the same RNN can generate multiple functionally feedforward patterns of activity as a result of dynamic shifts in the E/I balance imposed by the connectome of the RNN. We conclude that recurrent network architectures account for sequential neural activity, as well as for a fundamental signature of timing behavior: Weber's law.

# Quick Reference


# Comments


# Topics


# Tasks


----
# Notes



----
# Extracted Annotations