---
aliases:
  - Samuel J. Gershman, Nathaniel D. Daw 2017
type: citation
status: open
project: null
priority: null
creationtag: 2022-07-20 18:04
people:
  - Samuel J. Gershman
  - Nathaniel D. Daw
title: "Reinforcement learning and episodic memory in humans and animals: an
  integrative framework"
dateadd: 2022-07-20T15:57:39Z
citetype: journalArticle
year: 2017
journal: Annual review of psychology
URL: NA
DOI: 10.1146/annurev-psych-122414-033625
citekey: gershmanReinforcementLearningEpisodic2017
collection: Off of Petter 2018
tags:
  - NA
file: ""
---

# Reinforcement learning and episodic memory in humans and animals: an integrative framework
Read:: 
Print::  ‚ùå
Zotero Link:: NA
PDF:: NA
Files:: [Gershman_Daw_2017_Reinforcement learning and episodic memory in humans and animals.pdf](file:///home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/MX2AZV9M/Gershman_Daw_2017_Reinforcement%20learning%20and%20episodic%20memory%20in%20humans%20and%20animals.pdf); [PubMed Central Link](file://)
Reading Note:: [[Samuel J. Gershman, Nathaniel D. Daw 2017]]
Web Rip:: 
```dataview
TABLE without id
file.link as "Related Files",
title as "Title",
type as "type"
FROM "" AND -"ZZ. planning"
SORT file.cday DESC
```

# Abstract
We review the psychology and neuroscience of reinforcement learning (RL), which has witnessed significant progress in the last two decades, enabled by the comprehensive experimental study of simple learning and decision-making tasks. However, the simplicity of these tasks misses important aspects of reinforcement learning in the real world: (i) State spaces are high-dimensional, continuous, and partially observable; this implies that (ii) data are relatively sparse: indeed precisely the same situation may never be encountered twice; and also that (iii) rewards depend on long-term consequences of actions in ways that violate the classical assumptions that make RL tractable., A seemingly distinct challenge is that, cognitively, these theories have largely connected with procedural and semantic memory: how knowledge about action values or world models extracted gradually from many experiences can drive choice. This misses many aspects of memory related to traces of individual events, such as episodic memory. We suggest that these two gaps are related. In particular, the computational challenges can be dealt with, in part, by endowing RL systems with episodic memory, allowing them to (i) efficiently approximate value functions over complex state spaces, (ii) learn with very little data, and (iii) bridge long-term dependencies between actions and rewards. We review the computational theory underlying this proposal and the empirical evidence to support it. Our proposal suggests that the ubiquitous and diverse roles of memory in RL may function as part of an integrated learning system.

# Quick Reference


# Top Comments


# Topics


# Tasks


----
# Notes


----
# Extracted Annotations and Comments