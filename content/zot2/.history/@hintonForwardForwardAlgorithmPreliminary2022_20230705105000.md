---

aliases: ["NA et al. (2022)",]
aliases: ["Hinton (2022)",]
type: citation
status: open
project: NA
priority: P5

creationtag: <% tp.file.creation_date() %>
creationtag: 2023-06-06 12:33
people: ["G. Hinton"]
title: "The Forward-Forward Algorithm: Some Preliminary Investigations"
dateadd: 2023-06-06T10:32:21Z
citetype: Preprint
year: 2022
journal: NA
URL: "NA"
DOI: "10.48550/arXiv.2212.13345"
citekey: hintonForwardForwardAlgorithmPreliminary2022
collection: NA
tags: [Computer Science, Machine Learning]
---

# The Forward-Forward Algorithm: Some Preliminary Investigations
Read:: 
- [ ] The Forward-Forward Algorithm: Some Preliminary Investigations G. Hinton 2022 🛫 2023-06-06 !!2 #citation #reading [link](https://todoist.com/showTask?id=6982838392) #todoist %%[todoist_id:: 6982838392]%%
Print::  ❌
Zotero Link:: [arXiv.org Snapshot](zotero://open-pdf/library/items/PBWNMGIR); [Hinton_2022_The Forward-Forward Algorithm.pdf](zotero://open-pdf/library/items/TH9DUUR3)

PDF:: NA
PDF:: [[Hinton_2022_The Forward-Forward Algorithm.pdf]]
Files:: [arXiv.org Snapshot](file:///C:%5CUsers%5Cmichaelt%5CInsync%5Cm@tarlton.info%5CGoogle%20Drive%5C06.%20Zotero%5Cstorage%5CPBWNMGIR%5C2212.html); [Hinton_2022_The Forward-Forward Algorithm.pdf](file:///C:%5CUsers%5Cmichaelt%5CInsync%5Cm@tarlton.info%5CGoogle%20Drive%5C06.%20Zotero%5Cstorage_new%5CarXiv_2022%5CHinton_2022_The%20Forward-Forward%20Algorithm.pdf)
Reading Note:: 
Web Rip:: 

```dataview
TABLE without id
file.link as "Related Files",
title as "Title",
type as "type"
FROM "" AND -"ZZ. planning"
WHERE citekey = "hintonForwardForwardAlgorithmPreliminary2022" 
SORT file.cday DESC
```


> [!Excerpt] Abstract
> The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth further investigation. 
> 
> The Forward-Forward algorithm replaces the forward and backward passes of backpropagation by two forward passes, one with positive (i.e. real) data and the other with negative data which could be generated by the network itself. 
> 
> Each layer has its own objective function which is simply to have high goodness for positive data and low goodness for negative data. The sum of the squared activities in a layer can be used as the goodness but there are many other possibilities, including minus the sum of the squared activities. If the positive and negative passes could be separated in time, the negative passes could be done offline, which would make the learning much simpler in the positive pass and allow video to be pipelined through the network without ever storing activities or stopping to propagate derivatives.


# Quick Reference

# Top Comments
Let's say grey is for overall comments
 

# Tasks

# Topics


# Further Reading 
 

----
# Notes


----
# Extracted Annotations and Comments


# Figures