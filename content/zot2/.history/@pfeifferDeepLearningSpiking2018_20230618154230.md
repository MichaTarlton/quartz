---
aliases:
  - Michael Pfeiffer, Thomas Pfeil 2018
type: citation
status: open
creationtag: 2022-06-17 12:18
people:
  - Michael Pfeiffer
  - Thomas Pfeil
title: "Deep Learning With Spiking Neurons: Opportunities and Challenges"
dateadd: 2022-05-11T08:00:08Z
citetype: journalArticle
year: 2018
journal: Frontiers in Neuroscience
URL: NA
DOI: NA
citekey: pfeifferDeepLearningSpiking2018
collection: SNN - RL
tags:
  - NA
file: ""
---

# Deep Learning With Spiking Neurons: Opportunities and Challenges
Read:: 
Project:: []
Print::  ‚ùå
- [ ] print 
Zotero Link:: NA
PDF:: NA
Files:: [Deep Learning With Spiking Neurons Opportunities and Challenges - 11.05.22.md](file:///home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/WSNMDLTK/Deep%20Learning%20With%20Spiking%20Neurons%20Opportunities%20and%20Challenges%20-%2011.05.22.md); [Pfeiffer_Pfeil_2018_Deep Learning With Spiking Neurons.pdf](file:///home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/7E5HHFFU/Pfeiffer_Pfeil_2018_Deep%20Learning%20With%20Spiking%20Neurons.pdf)
Reading Note:: [[Michael Pfeiffer, Thomas Pfeil 2018]]

# Abstract
Spiking neural networks (SNNs) are inspired by information processing in biology, where sparse and asynchronous binary signals are communicated and processed in a massively parallel fashion. SNNs on neuromorphic hardware exhibit favorable properties such as low power consumption, fast inference, and event-driven information processing. This makes them interesting candidates for the efficient implementation of deep neural networks, the method of choice for many machine learning tasks. In this review, we address the opportunities that deep spiking networks offer and investigate in detail the challenges associated with training SNNs in a way that makes them competitive with conventional deep learning, but simultaneously allows for efficient mapping to hardware. A wide range of training methods for SNNs is presented, ranging from the conversion of conventional deep networks into SNNs, constrained training before conversion, spiking variants of backpropagation, and biologically motivated variants of STDP. The goal of our review is to define a categorization of SNN training methods, and summarize their advantages and drawbacks. We further discuss relationships between SNNs and binary networks, which are becoming popular for efficient digital hardware implementation. Neuromorphic hardware platforms have great potential to enable deep spiking networks in real-world applications. We compare the suitability of various neuromorphic systems that have been developed over the past years, and investigate potential use cases. Neuromorphic approaches and conventional machine learning should not be considered simply two solutions to the same classes of problems, instead it is possible to identify and exploit their task-specific advantages. Deep SNNs offer great opportunities to work with new types of event-based sensors, exploit temporal codes and local on-chip learning, and we have so far just scratched the surface of realizing these advantages in practical applications.

# Quick Reference


# Top Comments


# Topics


# Tasks


----
# Notes


----
# Extracted Annotations and Comments