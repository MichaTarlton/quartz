---

aliases: ["NA et al. (2022)",]
aliases:
  - Liu et al. (2022) Human-Level Control Through Directly Trained Deep Spiking Q-Networks
type: citation
status: open
project: NA
priority: P5

creationtag: <% tp.file.creation_date() %>

people: ["G. Liu", "W. Deng", "X. Xie", "L. Huang", "H. Tang"]
creationtag: 2023-02-06 18:11
people:
  - G. Liu
  - W. Deng
  - X. Xie
  - L. Huang
  - H. Tang
title: Human-Level Control Through Directly Trained Deep Spiking $Q$-Networks
dateadd: 2023-02-01T12:51:00Z
citetype: Journal Article
year: 2022
journal: IEEE Transactions on Cybernetics

URL: "NA"
URL: NA
DOI: 10.1109/TCYB.2022.3198259
citekey: liuHumanLevelControlDirectly2022
collection: 01 Keep in Sight, DRL-SNN, PENG9560

tags: [NA]
tags:
  - NA
file: ""
---

# Human-Level Control Through Directly Trained Deep Spiking $Q$-Networks
Read:: 
- [ ] Human-Level Control Through Directly Trained Deep Spiking $Q$-Networks G. Liu, W. Deng, X. Xie, L. Huang, H. Tang 2022 ðŸ›« 2023-03-02 #reading #citation
Print::  âŒ
Zotero Link:: NA
PDF:: NA
Files:: [Liu et al_2022_Human-Level Control Through Directly Trained Deep Spiking $Q$-Networks.pdf](file:///C:%5CUsers%5Cmichaelt%5CInsync%5Cm@tarlton.info%5CGoogle%20Drive%5C06.%20Zotero%5Cstorage_new%5CIEEE%20Transactions%20on%20Cybernetics_2022%5CLiu%20et%20al_2022_Human-Level%20Control%20Through%20Directly%20Trained%20Deep%20Spiking%20$Q$-Networks.pdf); [preprint_Liu et al_2022_Human-Level Control Through Directly Trained Deep Spiking $Q$-Networks.pdf](file:///C:%5CUsers%5Cmichaelt%5CInsync%5Cm@tarlton.info%5CGoogle%20Drive%5C06.%20Zotero%5Cstorage%5CQNWWEUWG%5CLiu%20et%20al_2022_Human-Level%20Control%20Through%20Directly%20Trained%20Deep%20Spiking%20$Q$-Networks.pdf); [Semantic Scholar Link](file:///)
Reading Note:: [[G. Liu, W. Deng, X. Xie, L. Huang, H. Tang (2022)]]
Web Rip:: 

```dataview
TABLE without id
file.link as "Related Files",
title as "Title",
type as "type"
FROM "" AND -"ZZ. planning"
WHERE citekey = "liuHumanLevelControlDirectly2022" 
SORT file.cday DESC
```


> [!Excerpt] Abstract
> As the third-generation neural networks, spiking neural networks (SNNs) have great potential on neuromorphic hardware because of their high energy efficiency. However, deep spiking reinforcement learning (DSRL), that is, the reinforcement learning (RL) based on SNNs, is still in its preliminary stage due to the binary output and the nondifferentiable property of the spiking function. To address these issues, we propose a deep spiking Q -network (DSQN) in this article. Specifically, we propose a directly trained DSRL architecture based on the leaky integrate-and-fire (LIF) neurons and deep Q -network (DQN). Then, we adapt a direct spiking learning algorithm for the DSQN. We further demonstrate the advantages of using LIF neurons in DSQN theoretically. Comprehensive experiments have been conducted on 17 top-performing Atari games to compare our method with the state-of-the-art conversion method. The experimental results demonstrate the superiority of our method in terms of performance, stability, generalization and energy efficiency. To the best of our knowledge, our work is the first one to achieve state-of-the-art performance on multiple Atari games with the directly trained SNN.


# Quick Reference

# Top Comments

Let's say grey is for overall comments

# Tasks

# Topics


# Further Reading 
 

----
# Notes
Excellent addition to my needs. Keep in sight.
\[TLDR\] This work is the first one to achieve state-of-the-art performance on multiple Atari games with the directly trained SNN and proposes a directly trained DSRL architecture based on the leaky integrate-and-fire neurons and deep Q -network (DQN).

----
# Extracted Annotations and Comments


# Figures