---
aliases:
  - Bellec et al. 2020
type: citation
status: open
creationtag: 2022-06-17 11:41
people:
  - Guillaume Bellec
  - Franz Scherr
  - Anand Subramoney
  - Elias Hajek
  - Darjan Salaj
  - Robert Legenstein
  - Wolfgang Maass
title: A solution to the learning dilemma for recurrent networks of spiking neurons
dateadd: 2022-05-12T15:11:45Z
citetype: journalArticle
year: 2020
journal: Nature Communications
URL: NA
DOI: 10.1038/s41467-020-17236-y
citekey: bellecSolutionLearningDilemma2020
collection:
  - Asynchoronous neural activity
  - SNN - STDP
tags:
  - Electrical and electronic engineering
  - Learning algorithms
  - Network models
  - Neuroscience
  - Synaptic plasticity
  - eligibility trace
  - e-prop
file: ""
---

# A solution to the learning dilemma for recurrent networks of spiking neurons
Read:: 
Project:: []
Print::  ❌
- [ ] print 
Zotero Link:: NA
PDF:: NA
Files:: [Bellec et al_2020_A solution to the learning dilemma for recurrent networks of spiking neurons.pdf](file:///home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/V7R6KZFX/Bellec%20et%20al_2020_A%20solution%20to%20the%20learning%20dilemma%20for%20recurrent%20networks%20of%20spiking%20neurons.pdf); [Snapshot](file:///home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/UGZVBK9J/s41467-020-17236-y.html)
Reading Note:: [[Guillaume Bellec, Franz Scherr, Anand Subramoney, Elias Hajek, Darjan Salaj, Robert Legenstein, Wolfgang Maass 2020]]

# Abstract
Recurrently connected networks of spiking neurons underlie the astounding information processing capabilities of the brain. Yet in spite of extensive research, how they can learn through synaptic plasticity to carry out complex network computations remains unclear. We argue that two pieces of this puzzle were provided by experimental data from neuroscience. A mathematical result tells us how these pieces need to be combined to enable biologically plausible online network learning through gradient descent, in particular deep reinforcement learning. This learning method–called e-prop–approaches the performance of backpropagation through time (BPTT), the best-known method for training recurrent neural networks in machine learning. In addition, it suggests a method for powerful on-chip learning in energy-efficient spike-based hardware for artificial intelligence.

# Quick Reference


# Top Comments


# Topics


# Tasks


----
# Notes


----
# Extracted Annotations and Comments