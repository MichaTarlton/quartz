---
aliases: ["Eshraghian et al. (2023)",]
type: citation
status: open
project: NA
priority: P5

creationtag: <% tp.file.creation_date() %>
creationtag: 2023-05-25 14:29
people: ["J.K. Eshraghian", "M. Ward", "E. Neftci", "X. Wang", "G. Lenz", "G. Dwivedi", "M. Bennamoun", "D.S. Jeong", "W.D. Lu"]
title: "Training Spiking Neural Networks Using Lessons From Deep Learning"
dateadd: 2023-05-25T12:26:12Z
citetype: Preprint
year: 2023
journal: NA
URL: "NA"
DOI: "10.48550/arXiv.2109.12894"
citekey: eshraghianTrainingSpikingNeural2023
collection: SNN - DL
tags: [Computer Science - Emerging Technologies, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, SNN, DL, code, dev]
---

# Training Spiking Neural Networks Using Lessons From Deep Learning
Read::
- [ ] Training Spiking Neural Networks Using Lessons From Deep Learning J.K. Eshraghian, M. Ward, E. Neftci, X. Wang, G. Lenz, G. Dwivedi, M. Bennamoun, D.S. Jeong, W.D. Lu 2023 🛫 2023-05-25 #citation !!2 #reading [link](https://todoist.com/showTask?id=6929011388) #todoist  %%[todoist_id:: 6929011388]%%

Print::  ❌
Print:: ✔ 
Zotero Link:: [arXiv.org Snapshot](zotero://open-pdf/library/items/5X99I2FC); [Eshraghian et al_2023_Training Spiking Neural Networks Using Lessons From Deep Learning.pdf](zotero://open-pdf/library/items/MGPBPV43)

PDF:: NA

PDF:: [[2109.12894.pdf]]
Files:: [arXiv.org Snapshot](file:///C:%5CUsers%5Cmichaelt%5CInsync%5Cm@tarlton.info%5CGoogle%20Drive%5C06.%20Zotero%5Cstorage%5C5X99I2FC%5C2109.html); [Eshraghian et al_2023_Training Spiking Neural Networks Using Lessons From Deep Learning.pdf](file:///C:%5CUsers%5Cmichaelt%5CInsync%5Cm@tarlton.info%5CGoogle%20Drive%5C06.%20Zotero%5Cstorage_new%5CarXiv_2023%5CEshraghian%20et%20al_2023_Training%20Spiking%20Neural%20Networks%20Using%20Lessons%20From%20Deep%20Learning.pdf)
Reading Note:: 
Web Rip:: 

```dataview
TABLE without id
file.link as "Related Files",
title as "Title",
type as "type"
FROM "" AND -"ZZ. planning"
WHERE citekey = "eshraghianTrainingSpikingNeural2023" 
SORT file.cday DESC
```


> [!Excerpt] Abstract
> The brain is the perfect place to look for inspiration to develop more efficient neural networks. The inner workings of our synapses and neurons provide a glimpse at what the future of deep learning might look like. This paper serves as a tutorial and perspective showing how to apply the lessons learnt from several decades of research in deep learning, gradient descent, backpropagation and neuroscience to biologically plausible spiking neural neural networks. We also explore the delicate interplay between encoding data as spikes and the learning process; the challenges and solutions of applying gradient-based learning to spiking neural networks (SNNs); the subtle link between temporal backpropagation and spike timing dependent plasticity, and how deep learning might move towards biologically plausible online learning. Some ideas are well accepted and commonly used amongst the neuromorphic engineering community, while others are presented or justified for the first time here. The fields of deep learning and spiking neural networks evolve very rapidly. We endeavour to treat this document as a 'dynamic' manuscript that will continue to be updated as the common practices in training SNNs also change. A series of companion interactive tutorials complementary to this paper using our Python package, snnTorch, are also made available. See https://snntorch.readthedocs.io/en/latest/tutorials/index.html .


# Quick Reference

# Top Comments
Let's say grey is for overall comments
 

# Tasks

# Topics


# Further Reading 
 

----
# Notes


----
# Extracted Annotations and Comments


# Figures