---
aliases:
  - Matthew Botvinick, Jane X. Wang, Will Dabney, Kevin J. Miller, Zeb
    Kurth-Nelson 2020
type: citation
status: open
creationtag: 2022-06-17 11:42
people:
  - Matthew Botvinick
  - Jane X. Wang
  - Will Dabney
  - Kevin J. Miller
  - Zeb Kurth-Nelson
title: Deep Reinforcement Learning and its Neuroscientific Implications
dateadd: 2022-05-15T19:04:48Z
citetype: journalArticle
year: 2020
journal: arXiv:2007.03750 [cs, q-bio]
URL: NA
DOI: NA
citekey: botvinickDeepReinforcementLearning2020
collection: NA
tags:
  - Computer Science - Artificial Intelligence
  - Computer Science - Machine Learning
  - Quantitative Biology - Neurons and Cognition
file: ""
---

# Deep Reinforcement Learning and its Neuroscientific Implications
Read:: 
Project:: []
Print::  ‚ùå
- [ ] print 
Zotero Link:: NA
PDF:: NA
Files:: NA
Reading Note:: [[Matthew Botvinick, Jane X. Wang, Will Dabney, Kevin J. Miller, Zeb Kurth-Nelson 2020]]

# Abstract
The emergence of powerful artificial intelligence is defining new research directions in neuroscience. To date, this research has focused largely on deep neural networks trained using supervised learning, in tasks such as image classification. However, there is another area of recent AI work which has so far received less attention from neuroscientists, but which may have profound neuroscientific implications: deep reinforcement learning. Deep RL offers a comprehensive framework for studying the interplay among learning, representation and decision-making, offering to the brain sciences a new set of research tools and a wide range of novel hypotheses. In the present review, we provide a high-level introduction to deep RL, discuss some of its initial applications to neuroscience, and survey its wider implications for research on brain and behavior, concluding with a list of opportunities for next-stage research.

# Quick Reference


# Top Comments


# Topics


# Tasks


----
# Notes
[Sunday 3:52 PM] Anis Yazidi 

Quoting from a paper from Neuron: 

"One important challenge, in this regard, is long-term temporal credit assignment, that is, updating behavior on the basis of rewards that may not accrue until a substantial time after the actions that were responsible for generating them. 

This remains a challenge for deep RL systems. 

Novel algorithms have recently been proposed (see, e.g., Hung et al., 2019), but the problem is far from solved, and a dialog with neuroscience in this area may be beneficial to both fields"




----
# Extracted Annotations and Comments