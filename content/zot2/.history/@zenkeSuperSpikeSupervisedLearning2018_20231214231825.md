

# SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks
Read:: 
- [ ] SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks F. Zenke, S. Ganguli 2018 ðŸ›« NA #reading #citation
Print::  âŒ

Zotero Link:: [PubMed entry](); [Zenke_Ganguli_2018_SuperSpike.pdf](zotero://open-pdf/library/items/F8PZS65B)

PDF:: NA
Zotero Link:: NA
PDF:
Files:: [PubMed entry](file:///); [Zenke_Ganguli_2018_SuperSpike.pdf](file:////home/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/AWQU9EEA/Zenke_Ganguli_2018_SuperSpike.pdf)
Reading Note:: [[F. Zenke, S. Ganguli (2018)]]
Web Rip:: 

```dataview
TABLE without id
file.link as "Related Files",
title as "Title",
type as "type"
FROM "" AND -"ZZ. planning"
WHERE citekey = "zenkeSuperSpikeSupervisedLearning2018" 
SORT file.cday DESC

> [!Excerpt] Abstract
```

# Abstract
A vast majority of computation in the brain is performed by spiking neural networks. Despite the ubiquity of such spiking, we currently lack an understanding of how biological spiking neural circuits learn and compute in vivo, as well as how we can instantiate such capabilities in artificial spiking circuits in silico. Here we revisit the problem of supervised learning in temporally coding multilayer spiking neural networks. First, by using a surrogate gradient approach, we derive SuperSpike, a nonlinear voltage-based three-factor learning rule capable of training multilayer networks of deterministic integrate-and-fire neurons to perform nonlinear computations on spatiotemporal spike patterns. Second, inspired by recent results on feedback alignment, we compare the performance of our learning rule under different credit assignment strategies for propagating output errors to hidden units. Specifically, we test uniform, symmetric, and random feedback, finding that simpler tasks can be solved with any type of feedback, while more complex tasks require symmetric feedback. In summary, our results open the door to obtaining a better scientific understanding of learning and computation in spiking neural networks by advancing our ability to train them to solve nonlinear problems involving transformations between different spatiotemporal spike time patterns.

# Quick Reference


# Top Comments

Let's say grey is for overall comments


# Topics


# Further Reading 
 

--
# Extracted Annotations and Comments


# Figures