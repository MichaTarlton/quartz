---
zotero-key: FP8J9EFA
zt-attachments:
  - "2759"
title: A New Look at Spike-Timing-Dependent Plasticity Networks for Spatio-Temporal Feature Learning
citekey: safaNewLookSpikeTimingDependent2021
aliases:
  - Safa et al. (2021)
people:
  - A. Safa
  - I. Ocket
  - A. Bourdoux
  - H. Sahli
  - F. Catthoor
  - G. Gielen
citetype: conferencePaper
year: 2021
tags: []
type: citation
status: open
project: NA
priority: P5
creationtag: 2023-12-03 21:25
---
# A New Look at Spike-Timing-Dependent Plasticity Networks for Spatio-Temporal Feature Learning
Read:: - [ ] Safa et al. (2021) - A New Look at Spike-Timing-Dependent Plasticity Networks for Spatio-Temporal Feature Learning 🛫2023-12-03 !!2 #rd #citation #todoist
Print::  ❌
Zotero Link:: [Zotero](zotero://select/library/items/FP8J9EFA) 
Files:: [attachment](<file:///C:/Users/michaelt/Insync/m@tarlton.info/Google%20Drive/06.%20Zotero/storage/PTY7KFYL/Safa%20et%20al_2021_A%20New%20Look%20at%20Spike-Timing-Dependent%20Plasticity%20Networks%20for%20Spatio-Temporal.pdf>)
Reading Note::
Web Rip::
url:: 

```dataview
TABLE without id
file.link as "Related Files",
title as "Title",
type as "type"
FROM "" AND -"ZZ. planning"
WHERE citekey = "safaNewLookSpikeTimingDependent2021" 
SORT file.cday DESC
```

> [!Excerpt] Abstract
> This work provides novel theoretical grounds for SNN and STDP parameter tuning which considerably reduces design time, and contributes to both ultra-low-power learning in neuromorphic edge devices, and towards a biologically-plausible, optimization-based theory of cortical vision. We present new theoretical foundations for unsupervised Spike-Timing-Dependent Plasticity (STDP) learning in spiking neural networks (SNNs). In contrast to empirical parameter search used in most previous works, we provide novel theoretical grounds for SNN and STDP parameter tuning which considerably reduces design time. Using our generic framework, we propose a class of global, action-based and convolutional SNN-STDP architectures for learning spatio-temporal features from event-based cameras. We assess our methods on the N-MNIST, the CIFAR10-DVS and the IBM DVS128 Gesture datasets, all acquired with a real-world event camera. Using our framework, we report significant improvements in classification accuracy compared to both conventional state-of-the-art event-based feature descriptors (+8.2% on CIFAR10-DVS), and compared to state-of-the-art STDP-based systems (+9.3% on NMNIST, +7.74% on IBM DVS128 Gesture). Our work contributes to both ultra-low-power learning in neuromorphic edge devices, and towards a biologically-plausible, optimization-based theory of cortical vision.
# Quick Reference

# Top Notes

# Tasks
















# Figures (blue)

> Fig. 2: Conceptual illustration of the LIF neuron and STDP learning. a) The LIF neuron is connected to a pre-synaptic spiking input sin. When the membrane potential V crosses the threshold μ, the neuron emits a spike σ = 1 and V is reset to zero. b) The weight Wij is modified according to the double exponential STDP rule (4) in function of the difference between the pre- and the post-synaptic spike times τij = tpost,i −tpre,j.
> **Page 3**
> 
> ---
> 	Fig 2
> ^VYCQ9PJMaPTY7KFYLp3

> [!Fig 2]
> ![[50 Reading/zotlit_plugin/ZtImgExcerpt/R7MLQGIQ.png]]
> **Page 3**
> 
> ---
> 	Fig 2
> ^R7MLQGIQaPTY7KFYLp3






