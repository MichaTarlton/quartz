{"/":{"title":"🪴 Quartz 3.3","content":"\n[[notes/My page]]\n\nHost your second brain and [digital garden](https://jzhao.xyz/posts/networked-thought) for free. Quartz features\n\n1. Extremely fast natural-language [[notes/search]]\n2. Customizable and hackable design based on [Hugo](https://gohugo.io/)\n3. Automatically generated backlinks, link previews, and local graph\n4. Built-in [[notes/CJK + Latex Support (测试) | CJK + Latex Support]] and [[notes/callouts | Admonition-style callouts]]\n5. Support for both Markdown Links and Wikilinks\n\nCheck out some of the [amazing gardens that community members](notes/showcase.md) have published with Quartz or read about [why I made Quartz](notes/philosophy.md) to begin with.\n\n## Get Started\n\u003e 📚 Step 1: [Setup your own digital garden using Quartz](notes/setup.md)\n\nReturning user? Figure out how to [[notes/updating|update]] your existing Quartz garden.\n\nIf you prefer browsing the contents of this site through a list instead of a graph, you see a list of all [setup-related notes](/tags/setup).\n\n### Troubleshooting\n- 🚧 [Troubleshooting and FAQ](notes/troubleshooting.md)\n- 🐛 [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n- 👀 [Discord Community](https://discord.gg/cRFFHYye7t)\n\n","lastmodified":"2023-07-25T13:18:04.755882863Z","tags":[]},"/notes/CJK-+-Latex-Support-%E6%B5%8B%E8%AF%95":{"title":"CJK + Latex Support (测试)","content":"\n## Chinese, Japanese, Korean Support\n几乎在我们意识到之前，我们已经离开了地面。\n\n우리가 그것을 알기도 전에 우리는 땅을 떠났습니다.\n\n私たちがそれを知るほぼ前に、私たちは地面を離れていました。\n\n## Latex\n\nBlock math works with two dollar signs `$$...$$`\n\n$$f(x) = \\int_{-\\infty}^\\infty\n    f\\hat(\\xi),e^{2 \\pi i \\xi x}\n    \\,d\\xi$$\n\t\nInline math also works with single dollar signs `$...$`. For example, Euler's identity but inline: $e^{i\\pi} = -1$\n\nAligned equations work quite well:\n\n$$\n\\begin{aligned}\na \u0026= b + c \\\\ \u0026= e + f \\\\\n\\end{aligned}\n$$\n\nAnd matrices\n\n$$\n\\begin{bmatrix}\n1 \u0026 2 \u0026 3 \\\\\na \u0026 b \u0026 c\n\\end{bmatrix}\n$$\n\n## RTL\nMore information on configuring RTL languages like Arabic in the [config](notes/config.md) page.\n","lastmodified":"2023-07-25T13:18:04.755882863Z","tags":[]},"/notes/My-page":{"title":"Untitled Page","content":"\n\n---\ntitle: Cool new page\nenableToc: false\ntype: log\nstatus: p0\npriority: p4\nproject: SBFA paper\ncreationtag: 2023-05-07 19:18\ntags: SBF, writing\npeople:\ndate:\n---\n\n\n\n# [[06.07.23]]\n## New #neuromorphics journal?\nSome guy posted this [JoVE | Peer Reviewed Scientific Video Journal - Methods and Protocols](https://app.jove.com/methods-collections/2680) in the SNUFA discord.\n\nMentioned that they are attaching a media element as well\n\n## Notes from Insomnia\nLooks like a good flow for the presentation \n\n### Neural Oscillations\n- Sub to Suprasecond range\n- Building supersecond cycling time cells from circuits of cells which fire in the microsecond range\n- Building towards to multi-second range and beyond is a key goal here\n- The only neural oscillation that is above one second is the [[Neural Oscillations#Infraslow (\u003c0.01 Hz)|Infraslow]] rhythms\n\t- Don’t know much about these or how the generate\n\n\u003e [!question] \n\u003e **What intervals to time-cells cycle at?**\n\u003e Check [[@melloScalablePopulationCode2015|Mello et al. (2015)]]\n\u003e - It says *“We found that neurons fired at delays spanning tens of seconds and that this pattern of responding reflected the interaction between time and the animals’ ongoing sensorimotor\n\u003e \n\u003e [[Neural representations of time, space and other continuous variables]] has a slide showing up to 10 sec\n\u003e - They cite a Mau et al. 2018\n\u003e \n\u003e [[@patonNeuralBasisTiming2018|Paton \u0026 Buonomano 2018]]\n\u003e - You need to pull from this\n\u003e - Argues for distributed time encoding\n\u003e - See: ![[@patonNeuralBasisTiming2018#^1b1ldv]]\n\u003e Follow up to main question\n\n### Striatal Beat Frequency\n- Model of coincidence detection and interval prediction \n- Very promising model\n- Recent variation (EIO) can produce the model with entrainment of theta and gamma waves\n\t- better yet offers a method scaling (I think)\n- Is this producing a time-cell?\n### Fixed-Interval Task\n- The point of the SBF is to reproduce animal behavior in a FIT (or Peak IT?)\n- This relies on mapping a “triggering” stimuli to restart the oscillators \n- However what and how does this occur?\n- Also relies on a “saving” of interval information to some “cold-storage”\n\t- This may be different for the EIO\n\n### Environmental Periodic events without initiation stimulus\n- Many events in a natural environment come without a stimulus\n- A non-biological example taken from automata theory is web-crawling\n\t- Where webpages will update their content with some unknown stochastic frequency\n\t- An RL automata agent will need learn this periodicity and act on it accordingly\n- Our model will learn for this\n### What Space does this Model occupy then?\n- This model sits somewhere in scope between the SBF (subsecond to minutes range) and longer scale rhythmic changes like circadian rhythms\n\t- Ideally it could scale to any time range\n- The idea is not to create episodic memories of singular stimulus to action mappings\n- But create internalized representations of an environmental time landscape, and perhaps map actions to that instead\n-\n### Why Am I Really Doing it this Way?\n- I want to focus on how networks learn from very simple network learning conditions\n- I want to be able to create flexible, distributed, and multiplexed informational representations\n- No cold storage\n\t- Is stored in some state of the network and thus its dynamics\n\t- Presumably stays in working memory until phase synchronization with long-term memory forming, slower rhythms is achieved\n- Non reliant on initial stimulus\n\t- I don’t have to worry about how the network learns to map a stimulus to a reset trigger\n- Continual learning, is not “off” or inactive until triggered\n\t- Instead is constant and informing the \n\t- I want to understand how networks learn based on very simple reward mechanics\n\n### Basic Automata (Weighted Vote)\n\n### Adding Receptive Fields\n\n### Adding Scaling\nSupe not done yet\n\n### Other Aspects\n#### Using RPE\n#### Using Decay\n\n#### Measuring Robustness\nThe ability to distribute the encoding of multiple time events with negligible loss to accuracy\nTest for:\n- Simultaneous periodic time events\n- Switching RPs\n\t- Normally covered by scaling tbh\n\t- Dependent on oscillator value distribution\n\n#### Oscillator Value Distributions\n- Primes\n- Uniform\n- 1-F distribution\n\t- Uniform form\n\t- Drawn with probability along curve\n#### Scaling Strategies\n#### Implementing in SNN with STDP\n\n\n# [[05.07.23]]\n- Build on [[Outline 2.1]]\n- Make a new outline\n\t- With the purpose of a presentation\n\n\n\n\n# [[03.07.23]]\n## Re-Review of [[@melloScalablePopulationCode2015|Mello et al. (2015)]]\n- I need more info on his **decoder**\n\n\n\n#### Figure 4 \n\n\u003e [!Figure 4]\n![[SBFA Paper Log-image-20230703140213444.png]]\n\u003e  Single-Trial Estimates of Elapsed Time Decoded from the Population Response Correlate with True Time during Initial Trials of 12-s and 60-s FI Blocks \n\u003e  **(A)** Decoded population estimates of elapsed time from reward in single trials, for the first seven trials of the 12-s FI block plotted against true time. Red traces indicate the mean of the population likelihood function, and the underlying heatmap indicates the population likelihood function. The last panel shows a seven-trial average likelihood function using the first seven trials of the 12-s block. \n\u003e  **(B)** Decoded estimates of elapsed time for the first seven trials of the 12-s FI block plotted on the same axis. Curves are quadratic fits to the mean likelihood function of each individual trial (red lines in first seven panels). Red curves represent early trials, and black curves represent later trials. \n\u003e  **(C)** Same description as in (A), but for the 60-s FI. \n\u003e  **(D)** Same description as in (B), but for the 60-s FI. See also Figure S4.\n\n- So according to A, we should see a relative recovery in 4 trials of 10 FI repetitions?\n\t- For our purposes that is 40 RPs\n\n### I’m skipping because I can’t focus rn\n\n## [[@tsaoNeuralBasesTiming2022|Tsao et al. (2022)]]\nMade a glossary page for this [[Tsao et al. (2022) - glossary]]\n- Asks if prospective timing is generally related to retrospective timing\n\t- To which, I would say yes\n\t- I’m actually not sure this is the correct framing they are using here\n\t- ~~Like if we are predicting an interval, then it is basically the same~~\n\t- No nvm, it’s the difference between temporal bifuraction task and PIT\n\t- But presumably the same neuron (MSNs) are being activated\n\t- They have an entire box explaining it\n\n#### ‘prospective timing’ and ‘retrospective timing’ terminology\n\u003e First, retrospective timing is operationally defined as the estimation of a duration when subjects are unaware beforehand that they will estimate the duration, whereas prospective timing is defined as estimation of duration when subjects are aware beforehand161. The logic of this operational definition is that, particularly during prospective timing, subjects have the opportunity to explicitly track the passage of time. Thus, in the case where estimation occurs after the duration has ended but subjects are already aware beforehand that they will eventually estimate duration, this would still be considered prospective timing.\n\u003e \n\u003e Second, ‘prospective timing’ and ‘retrospective timing’ refer specifically to the estimation of duration, even though timing encompasses temporal order in addition to duration. Whether there exists a similar distinction between temporal order based on ongoing events as opposed to memory of past events is unclear.\n\u003e \n\u003e Finally, ‘prospective timing’ overlaps with other commonly used terms such as ‘interval timing’ and ‘reward timing’, whereas ‘retrospective timing’ partially overlaps with ‘episodic timing’, and each has also been referred to as ‘experienced duration’ and ‘remembered duration’, respectively335.\n\n### Intro \n\n\u003e Early models proposed that the internal clock would be implemented through a pacemakeraccumulator mechanism11–13 in which pulses generated by a central pacemaker would be integrated by an accumulator to generate estimates of time. However, outside the circadian system14,15, evidence for biological implementation of such a mechanism has been missing.\n - I don’t get this Gu et al. which is their citation directly refutes this idea\n\n\n#### Figure 2\n\n\u003e [!Figure 2]  Neural trajectories during prospective timing. \n\u003e **a** | The activity of a population of neurons, or population state, at a given moment can be depicted as a point within a state space where each axis corresponds to the firing rate of a specific neuron. \n\u003e \n\u003e In this example, there are three neurons, so the state space is three-dimensional. \n\u003e As the firing rates of the three neurons change across time, so does the population state, tracing out a trajectory, in this case spanning three time points (T1, T2 and T3). \n\u003e \n\u003e **b** | For a population consisting of N cells, the state space is N-dimensional. Dimensionality reduction can be used to reduce noise and to project data onto specific subspaces, and often it is helpful to apply dimensionality reduction techniques to more easily identify important features of neural trajectories. \n\u003e \n\u003e In this cartoon example, dimensionality reduction reveals a simpler trajectory within a two-dimensional space. \n\u003e \n\u003e **c** | Different trajectory features are used for sensory timing, motor timing and temporal expectation. For sensory timing of different durations (indicated by different shades of grey), a common trajectory progresses at a constant speed (starting at a common population state and reaching a common intermediate state over the same amount of elapsed physical time, indicated in blue) but stops at different terminal states for specific durations (indicated by different shades of red).\n\u003e \n\u003e For motor timing of different durations (indicated by different shades of grey), a common trajectory progresses at different speeds (starting at a common population state and reaching different intermediate population states over the same amount of elapsed physical time, indicated in blue) to reach a common terminal state (different durations indicated by different shades of red). \n\u003e \n\u003e For temporal expectation, a trajectory begins to evolve following the start of a fixed temporal structure, and reaches a specific state in accordance with this temporal structure. In the illustrated example, the temporal structure is defined by a cue which occurs at a fixed interval following a start signal, and the trajectory reaches a particular set of states (indicated in purple) at the time of the cue. This expectation-related internal state may then be reflected in an altered response criterion or modulation of sensory representations, for example. \n\u003e \n\u003e **d** | Left, structure of ‘ready, set, go’ sensorimotor timing task. Monkeys are presented with a sample interval **ts**, which they reproduce as **tp** through the timing of a motor action. \n\u003e \n\u003e Top centre, reward (green shading) is a function of the relative error between ts and tp. \n\u003e \n\u003e Bottom centre, the set of sample intervals used. \n\u003e \n\u003e Right, behaviour from an example monkey illustrating that animals are able to carry out both sensory timing and motor timing accurately in order to reproduce presented intervals. Dots indicate individual trials, and circles indicate average tp per ts. \n\u003e \n\u003e **e** | Neural trajectories during estimation (left) and production (right) epochs, based on activity recorded from the dorsomedial frontal cortex. These two sets of trajectories illustrate how prospective timing is accomplished through population state dynamics: specific durations are associated either with specific population states along the trajectory (estimation epoch) or specific trajectory speeds (production epoch). \n\u003e \n\u003e Triangles indicate ‘ready’, circles indicate ‘set’, squares indicate ‘go’ and small circles indicate neural states at 40-ms increments. Dim, dimension; PC, principal component. Parts d and e adapted with permission from reF.56, Elsevier.\n\n- Lmao fuck me they are using PCA dim. reduc. method\n\t- Which of course could mean \n\n## Writing ideas\n- Oscillatory processes set the foundation for the continuation and homeostasis of an organism\n\t- Abstractly, this represents the organism as occupying an stable attractor optimization in its environment\n\t\t- Which we may call characterize as teh “default state network” for the sake drawing an analogue in oscillations in observed neural data \n\t- Cardiac, Pulmonary, Metabolic, Circadian\n\t- As the organism scale increases, task specific modules isolate and take on their own specific rhythms\n\t- That still needs to relate to the rhythms of the whole\n\t- Both contributing to the changing greater loop, and taking instruction from \n- It follows that rhythmic processes set the basis of many biological functions\n- And that rhythmic process related to other rhythmic processes in the organism but some direct relational encoding between respective points in the phase procession of the rhythmic processes in the presence of important stimuli\n- Further, it is necessary to the stable organism to remap the relation of phase processions in a changing dynamic environment\n- As well as allow for some deviation in accuracy to allow some “exploration” of environmental conditions\n\n### Dopaminergic response\nAs reward becomes expected, the anticipatory firing begins tor precede the reward stimulus\nThus perhaps the drift of this response is somehow due to STDP\nHow would this work?\n- The neurons which fire in advance of the correct stimulus are increased in weight\n- Thus possibly some drift of the firing neuron to earlier firing neurons increases\n- Disinhibition of earlier firing inhibitory neurons (ones that fire after)\n- Later firing inhibitory neurons increase?\n- \n\n# [[27.06.23]]\n## Finishing up on [[@cohenItTime2011|Cohen (2011)]] from yesterday\nI left off at section ***How to study time-based processing schemes***\nAnd skipped over the next few sections and straight to conclusion\n\u003e Here it is argued that considerable neural information is embedded in the rich temporal landscape of electrophysiological dynamics, that much of this information may be lost when confining analyses to spatial dimensions, and that at least some of this information can be extracted non-invasively in humans using EEG and MEG. Approaches and analyses focused on temporal dynamical coding schemes will not render useless other approaches that are based on different (e.g., spatial) assumptions of neurocognitive function. However, ideas about time-based information coding schemes, and the approach of examining the temporal dynamics of brain electrical activity, are an important next step in theoretical and empirical human neuroscience developments. This nascent but growing literature on human neural temporal dynamics will provide a new impetus in uncovering fundamental neurocognitive mechanisms, linking research in humans to that in animals, and improving clinical diagnosis and treatment assessment. It’s about time.\n\n## Need to describe method for scaling and distribution of oscillators\nWhat if I checked out [[@melloScalablePopulationCode2015]] again?\n\n\n# [[26.06.23]]\n## Picking back up at section 7.3\n[[Declarative Memory]]\n\n## Models of forgetting - Section 7.4\nOk apparently they do have some modeling of holding multiple items in relation to a time period and how they might interfere to cause forgetting\n\n\u003e Simultaneous maintenance of different frequencies of theta oscillations (representing multiple items) would be easily disrupted by the interactions from other neuronal groups, especially when the two neuronal groups are tightly connected to each other—a result consistent with interference theory.\n\nAlso, *multiple EIO neuronal groups*.\n\n### time-based resource-sharing (TBRS) model #tp\n\u003e a time-based resource-sharing (TBRS) model that explains how forgetting is time related (Barrouillet et al., 2004) as well as the manner in which time plays a crucial role in working memory load (Barrouillet et al., 2007).\n\n\u003e Moreover, the TBRS model of working memory (Barrouillet et al., 2004, 2007) suggests that forgetting is time related such that the proportion of time capturing attention for each item is crucial to memory maintenance. This claim is consistent with the hybrid EIO model to the extent that it predicts the close relationship between interval timing and multiple-item working memory.\n\n\u003e Similarity-based interference theory proposes that maintained representations compete with other representations held in working memory, which could be similar and/or stronger, and result in interference and forgetting (Nairne, 1990; Oberauer and Kliegl, 2006; Saito and Miyake, 2004). The observation of proactive and retroactive interference (e.g., interference from prior trials in the case of proactive interference or interference from later trials in the case of retroactive interference) on current trials and increased interference with higher similarity support this proposal. Oberauer and Kliegl (2001, 2006) have provided further support for the interference model by fitting the time-accuracy data from a working memory task with a nonlinear mixed-effects model. The basic idea underlying this study was that more similar conditions provoke more interference because interference arises from overlapping features of item representation, and the estimated interference successfully accounted for the time-accuracy data in the working memory paradigm, whereas decay theories could not account for the time-accuracy data. However, as a contradictory point to this argument, Portrat et al. (2008) showed that a time-related decay effect is present as a function of processing time and recall performance in a different working memory paradigm, consistent with the TBRS model proposed by Barrouillet et al. (2004). However, these decay and interference hypotheses, which provide seemingly contradictory accounts for the loss or inability to access stored information, may be supported by the same neuronal properties (Jonides et al., 2008).\n\n\n\u003e For example, if the population neurons receive synchronized 6-Hz IO, the 7-Hz theta frequency encoding item 1 would be mainly reactivated at 1.5, 2.5, 3.5 s and so on (entrained within a 1-Hz delta oscillation) while the 8-Hz theta frequency encoding item 2 would be reactivated at 1.25, 1.75, 2.25 s and so on (entrained within a 2-Hz delta oscillation). In this sense, the time should be divided for the reactivations of each item to reduce the temporal overlap of reactivations between multiple items, so the restriction for the multiple-item maintenance originates from the temporal resource sharing (see Buhusi and Meck, 2009a) as proposed by the TBRS model.\n\nSo we can say that the weights of our oscillators is the attention and when giving to differing RPs the attention is divided, such that we should see similar interference pattern to the reward “memory” retrieval.\n\n## In absence of stimulus\n\u003e This hybrid model proposes the shared neural-oscillation properties underlying interval timing and working memory. **Even in the absence of an ongoing stimulus, neural oscillations in the brain continue in time, and this property would explain how we can perceive time and maintain information in the brain**. Certain frequency ranges of oscillation would include the specific dimension of information; such as theta activity entrained in delta for duration information and gamma activity entrained in theta for other stimulus attributes (e.g., pitch). In this way, interval timing and working memory would originate from the same cortical representations, but the specific connections between striatal and cortical neurons would be able to extract the different dimensions of that information.\n\nSo can we say this is a model of ongoing time oscillations?\n\n## Closing remarks on importance of oscillatory study\n\n\u003e recent focus on the temporal/oscillatory properties of brain and behavior has opened up another dimension for understanding the cognitive architecture of the brain (e.g., Cohen, 2011). Interval timing and working memory in particular share the characteristic that some internal process must continue over the course of time regardless of the existence of an external stimulus.\n\n\u003e spatio-temporal patterns of activation supporting these cognitive functions are sustained in neural networks over a time and these neural networks can be managed through the oscillatory fluctuations that reside in the recurrent networks. Because of the importance of these neural dynamics, the temporal/oscillatory properties of the brain should be emphasized in future studies of interval timing, attention, and working memory (see, for example, Cohen, 2011;Henry and Herrmann, 2014; Lake et al., 2014; Rohenkohl and Nobre, 2011; Rohenkohl et al., 2012)\n\n\u003e it has been hypothesized that the slower-frequency oscillations are involved in long-range communication in the brain (e.g., Buzsáki, 2006; Buzsáki and Draguhn, 2004; Buzsáki et al., 2012; Murray et al., 2014).\n- Lower frequencies correlate to “higher” or larger scale brain comms\n\n## Picked up two references I need to check\n[[@collinsHowMuchReinforcement2012]]\n[[@cohenItTime2011]]\n\n\n## [[@cohenItTime2011]]\n\u003e Here I will argue that too much attention has been focused on investigating neurocognitive function based on attempts to localize processes in space (i.e., functional localization). Instead, fruitful insights might arise from considering time to be an important factor in neurocognitive function. Indeed, for some neurocognitive processes, time may be as important, or possibly more important, than space in terms of the underlying neurocomputational mechanisms.\n- Good citation for how time has not been a matter of focus\n\n\n\u003e It is likely that the brain uses more dimensions for information processing than just space and activation magnitude. This is not meant to imply that space is irrelevant for information coding/processing, or that functional localization is inappropriate or invalid. Rather, after this initial period of studying functional localization and learning about its merits and limitations, it is perhaps useful to consider time as an important factor\n\n\u003e time may be as important – if not more important – than space for information processing, particularly at the level of small populations of cells (spatial scale of millimeters to a few centimeters). As described below, “time” refers to rapid dynamics in electrochemical signals that are often but not necessarily oscillatory\n\n\u003e Time as latency in functional MRI (e.g., the hemodynamic response peaks about 6–8 s after a stimulus) or an event-related component (e.g., the average voltage deflection 300–600 ms after a stimulus) is not taking into account the rich information that appears to be embedded in the temporal dynamics of neural activity.\n\n### several empirical and theoretical reasons why time may be in important factor in neural information processing\n\n\u003e **(1)** There appears to be information carried in the precise timing of activity within and across physically separated areas of the brain that cannot be measured by overall activity levels in any individual brain region. “Information” here can refer simply to quantifiable measures of brain activity that predict the cognitive state or behavioral response of the subject. In some cases, temporal dynamics of neural activity are significantly related to the task events while the overall amount of activity averaged over time is not. These kinds of results provide direct evidence that information in the brain is embedded in the rich temporal landscape of electrophysiological activity, and is lost when averaging activity over larger periods of time. Examples will be outlined in a subsequent section.\n\n\u003e **(2)** In an information-theoretic sense, time provides a large number of possibilities for information to be represented and processed continuously, rapidly, and simultaneously (in parallel) in multiple functionally distinct networks that overlap in time and space. Time provides a rich source of complex multi-dimensional data in which information can be represented and processed. **The large amount of information provided by the temporal dynamics of neural activity arises in part because electrophysiological activity of the brain is strongly oscillatory**. These oscillations reflect rhythmic fluctuations in the excitability of populations of neurons (Tiesinga et al., 2008; Wang, 2010).\n\n\u003e Oscillations occur in multiple temporal and spatial scales, ranging from ultra-slow oscillations with a periodicity of tens of seconds over much of the cortex during deep sleep (Steriade, 2006) to ultra-fast oscillations with a periodicity of a few milliseconds within patches of somatosensory cortex (Curio, 2000). Oscillations that seem most relevant for cognitive processes range from delta (∼1–4 Hz) and theta (∼4–8 Hz) to gamma (∼30–100 Hz; for general reviews of neural oscillations, see Varela et al., 2001; Buzsaki and Draguhn, 2004; Traub et al., 2004).\n\n\u003e Because activity in one frequency band may occur independently of, and in parallel with, activity in other frequency bands, there is considerable bandwidth for information processing. For example, it has been suggested that multiple alpha sub-bands can be functionally dissociated in their roles in memory processes (Klimesch et al., 2007). Thus, if different neurons are “tuned” to different frequency bands (Jacobs et al., 2007), multiple functionally distinct neural networks can spatially coexist and be dissociated according to frequency band or spatiotemporal patterns (Akam and Kullmann, 2010).\n\n\u003e from the activity recorded from a single electrode, there are already multiple domains of information, including \n\u003e **frequency (the speed of the oscillation**), \n\u003e **power (the amount of the energy in a frequency band at a point in time**), and \n\u003e **phase angle (the position of the oscillation along the sine wave, driven by the state of excitation of the population of neurons**; Figure 2; see also Makeig et al., 2004).\n\u003e And because these dimensions are largely independent of each other, a single electrode in a single location in the brain can measure multi-dimensional local neural dynamics.\n\n\u003e **(3)** There is arguably selection pressure for individuals and species carrying neural systems that can decode the sensory world, make decisions, and adapt behavior faster and more efficiently.\n- The rest of this section didn’t add anythin especially interesting other than discussing natural pressure for quick response times\n\n\u003e **(4)** Neural activity is inextricably linked to cognition and behavior in time, but not in space.\n\n\u003e The fact that brain activity is time-locked, rather than space-locked, to behavior implies that time will be highly informative about behaviorally relevant neurocognitive mechanisms. The brain does indeed exhibit some spatial relationships with the body (e.g., homuncular organization of sensorimotor regions, retinotopic organization of visual areas), although these examples still exhibit some arbitrary relations to behavior, such as the left–right and up–down crossovers.\n\n\u003e **(5)** Controversies develop in cognitive neuroscience over the precise functional role of a specific region, but some of these controversies may be moot because multiple functionally distinct neural networks may coexist in the same space. Indeed, in these cases, empirical evidence may seem conflicting because different theories can be supported by different experiments.\n\n\u003e it seems likely that functionally different networks can emerge from the same population of anterior cingulate cortex neurons, depending on task demands (Fujisawa et al., 2008).\n\n\u003e In other words, rather than attempting to resolve a grandunified-theory for the function of a region of the brain (in this example, the anterior cingulate cortex), attention might be better spent trying to understand how that area may utilize temporal schemes to compute and coordinate the diverse functions suggested by empirical evidence.\n- This is better emphasized by the fact that neuronal circuits are highly recurrent and deeply entangled, meaning that computation and information is being encoded in high dimensional dynamics of the activity which shares multiple functional attributes simultaneously.\n\n### examples oF time-embedded inFormation in human electrophysiological activity\nI was looking for something on coding embeddings\n\n\u003e Although the literature on time-based coding schemes and sophisticated analyses of electrophysiological data is overshadowed by the literature on fMRI-based localization studies, **there are too many relevant and insightful findings to discuss all them all here. Instead, this section will highlight three examples** of how mathematical analyses of the temporal dynamics of human electrophysiological recordings have shed insight into neurocognitive function. These examples also illustrate cases in which standard localization- and hemodynamic-based analyses would be unlikely to reveal these brain dynamics (e.g., because no overall increase in space-averaged activity occurs).\n\n#### Cross-frequency coupling #tp\n\u003e **(1)**  Cross-frequency coupling refers to a relationship between activities in two different frequency bands. For example, the power of gamma (∼30–80 Hz) oscillations may vary as a function of the phase of theta (∼4–8 Hz). Cross-frequency coupling may be used for information coding if the lower frequency oscillations coordinate the activity of sub-populations of cells that use higher frequency oscillations to process information.\n\n\u003e There are several ways in which cross-frequency coupling can be quantified (Mormann et al., 2005; Canolty et al., 2006; Cohen, 2008; Tort et al., 2010); different methods may be suited for different purposes, but all methods generally test for a modulation of activity in one frequency band as a function of activity in another (typically, relatively lower) frequency band.\n\n\u003e There are several ways in which cross-frequency coupling can be quantified (Mormann et al., 2005; Canolty et al., 2006; Cohen, 2008; Tort et al., 2010); different methods may be suited for different purposes, but all methods generally test for a modulation of activity in one frequency band as a function of activity in another (typically, relatively lower) frequency band.\n- [[@lismanThetaGammaNeuralCode2013|Lisman and Jensen (2013)]]\n\t- References another paper from Lisman but I think it’s basically the same idea\n\t- Directly related to the EIO-SBF as it entrains with this exact rhythms\n\n\n#### Inter-regional oscillatory synchronization #tp\n\u003e **(2)** In addition to dynamics across frequency bands within the same region of space, information may be embedded in the temporal relationship of activity over space. Inter-regional phase synchronization (a frequency band-specific measure of functional connectivity) may underlie information transfer and co-processing (Knight, 2007; Womelsdorf et al., 2007).\n- Also mentioning *long range synchronization* \n\n\u003e And because changes in phase synchronization may occur without any concomitant changes in power (Heinzle et al., 2007), there might be information embedded in the temporal relationship between areas that is not localized to either region alone.\n\u003e \n\u003e For example, inter-regional oscillatory synchronization may be the mechanism by which the medial frontal cortex interacts with other brain systems, such as lateral prefrontal cortex to implement cognitive control after errors in speeded reaction-time (Hanslmayr et al., 2008; Cavanagh et al., 2009) or reinforcement learning (Cavanagh et al., 2010) tasks, with occipital cortex to bias sensory processing during go/no-go tasks in which no-go cues were difficult to perceive (Cohen et al., 2009d), or with the nucleus accumbens during reinforcement learning and reward anticipation (Cohen et al., 2009b, 2011).\n\n#### Microstates and other transient electrophysiological events #tp\n\u003e **(3)** Microstates refer to brief periods of cortical electrophysiological activity that are topographically stable over tens to hundreds of milliseconds (Lehmann et al., 2006). Microstates fluctuate 1–2 orders of magnitude faster than the hemodynamic response, and have been linked to visual perception, error processing, and resting state (Muller et al., 2005; Britz and Michel, 2010).\n\n\u003e They are sometimes accompanied by hemo-dynamic responses (Britz et al., 2010; Musso et al., 2010). Other brief cortical events include endogenous “bursts” of frontal alpha asymmetry (Allen and Cohen, 2010) that have been linked to depression. Transient bursts of synchronized electrophysiological activity also occur during sleep, namely spindles and ripples, which have been linked to memory formation and dream recall (Axmacher et al., 2008).\n\n## [[@collinsHowMuchReinforcement2012]]\n- RL\n- Working memory\n\nThey use a softmax func to choose an action:\n\u003e where $a_{\\mathrm{RL}}$ is the learning rate. Choices are generated probabilistically as a function of the difference in $Q$ values between the available actions using the softmax choice rule:\n\u003e $$\np(a \\mid s)=\\frac{\\exp \\left(\\beta_{R L} Q(s, a)\\right)}{\\sum_i \\exp \\left(\\beta_{R L} Q\\left(s, a_i\\right)\\right)}\n$$\nwhere $\\beta_{\\mathrm{RL}}$ is an inverse temperature determining the degree to which differences in $Q$ values are translated into a more deterministic choice.\n- Perhaps I could do something similar.\n- What exactly does this do?\n\n\u003e **The number of stimuli, denoted as set size $n_S$,**\n\n### Forgetful reinforcement learning (RLF) model #tp\n\u003e In this model, $Q$ learning and action selection occur as in Eqns 1 and 2 from model RL2. Additionally, we include a supplementary effect of forgetting across time; at each trial, for all stimulus-action pairs ( $S$, a), we decay $Q$ values towards their initial values\n\u003e $$\n Q(s, a) \\leftarrow Q(s, a)+\\epsilon \\times\\left(Q_0-Q(s, a)\\right)\n $$\n\u003e where $Q_D=1 / n_A$ is the initial $Q$ value for all actions, representing random policy, and $\\epsilon$ controls the degree of forgetfulness.\n\u003e \n\u003e Thus, with increasing delay between repeated encounters with the same stimulus, the more the learned $Q$ values will have decayed. Consequently, with $\\in\u003e0$, this three-parameter model predicts a decrease in performance in higher set-size blocks, due solely to the increased average delay between stimulus repetitions for higher set sizes (see Fig. 4).\n\n#### Figure 4.\n![[image-20230626190944890.png]]\n\n\u003e **Fig. 4**. Model results. Learning curves as a function of set size for each model, generated using best-fit parameters for each subject given the model. Models: RL2, two-parameter RL model; WM, pure WM model; RL6, RL model with five learning rates + one softmax temperature; RLF, three-parameter forgetful model; RL + WM, mixture RL and WM model. Subjects, observed learning curves across all subjects (from Fig. 2).\n\n### Reinforcement learning + working memory model ($\\mathrm{RL}+\\mathrm{WM}$) #tp\nIn the $\\mathrm{RL}+\\mathrm{WM}$ model, action selection derives from a mixture of a pure simple RL model (i.e. RL2 ) [By RL2 they meal an RL with two parameters (s, a)] applied to all set sizes [number of stimuli], together with a limited capacity WM component. \n\nWe simulated WM as the encoding of an observed event that, if maintained in memory, could serve to immediately and robustly affect behavior.[ WHAT THE FUCK DOES THIS MEAN] That is, perfect memory could be represented by a $Q$ learning system with a learning rate of 1 (which is optimal for a deterministic task). However, memory degrades over time and is capacity-limited. For the degradation effect, we implement a decay as in the RLF model so that, after RL update, for all $(s, a)$ at each trial\n$$\nQ_{\\mathrm{WM}}(s, a) \\leftarrow Q_{\\mathrm{WM}}(s, a)+\\epsilon \\times\\left(\\frac{1}{n_{\\mathrm{A}}}-Q_{\\mathrm{WM}} Q(s, a)\\right)\n$$\nThe probability of action selection according to the $\\mathrm{WM}$ component is then $p_{\\mathrm{WM}}(a)=$ $\\operatorname{softmax}\\left(\\beta_{\\mathrm{WM}} Q_{\\mathrm{WM}}\\right)$. As in earlier models, the probability of action selection for the RL component is $p_{\\mathrm{RL}}(a)=\\operatorname{softmax}\\left(\\beta_{\\mathrm{RL}} Q_{\\mathrm{RL}}\\right)$. As stated thus far, the WM component captures forgetting but does not yet account for the known limited capacity of WM. This capacity limitation is factored into the mixture weight $W(t)$ determining the probability that action selection is governed by the RL or WM component\n$$\np(a)=(1-w(t)) p_{\\mathrm{RL}}(a)+w(t) p_{\\mathrm{WM}}(a)\n$$\n\n# [[22.06.23]]\n## Left off at Sec. 6.3 in [[@guOscillatoryMultiplexingNeural2015a]]\nThis is really long and there are only 2 hours left in the day. Time to go home.\n\nSee how the gamma and theta cycles are described here:\n\u003e In relation to the importance of theta and gamma oscillations for working memory, Lisman and [[Declarative Memory]]colleagues (e.g., Lisman, 2005, 2010; Lisman and Idiart, 1995) proposed an oscillatory model of working memory. According to this model, gamma oscillations entrained within theta could represent maintained memory by repetitively activating relevant neuronal groups with temporal precision, and multiple items can be maintained in working memory by the multiple cycles of sequential gamma oscillations entrained within a theta oscillation (Jensen, 2006; Jensen and Lisman, 1998; Lisman, 2010; Lisman and Idiart, 1995—Fig. 3).\n![[image-20230622133319494.png]]\n\n\u003e For example, different items in memory are represented by different neuronal groups (e.g., spatial pattern of cells), and each neuronal group is activated during each gamma cycle. Because multiple **gamma cycles of 30–80 Hz** are present within each **theta cycle of 4–10 Hz**, multiple item information/memory represented by multiple gamma cycles is activated every theta cycle so that they can be maintained as separated from each other within a specific temporal sequence.\n\nSo basically sequences are mapped to the larger theta wave, and the individual items of the sequence are mapped to the smaller gamma waves\n\nPhase precession of cells wrt to theta waves. I.e. you can measure distance traveled via cell firing in location in theta phase:\n\u003e the firing of place cells shows theta-phase precession during spatial navigation (Fig. 4A). For example, as a subject reaches its target area, the place-cell firing occurs at earlier phases of the theta oscillation of the LFP so that the firing phase of the cell reflects the relative distance that the subject has traveled through the cell’s place field (e.g., firing at late phases of theta indicates that the subject has just entered the place field—Burgess et al., 1994; Skaggs et al., 1996).\n\nSee [[Excitatory - Inhibitory Oscillation (EIO-SBF)#guOscillatoryMultiplexingNeural2015a Gu et al 2015|Figure 5 of Gu et al. and their description of the EIO model]]\n- I have several comments on figure 5\n- Like, why, to all of it\n- They do EIO at multiple scales like four times and keep introducing new rythms\n- Sorta starting to make sense\n\t- If I am understanding it correctly each of the larger delta and theta waves are emergent descriptors of the underlying gamma waves\n\t- Or not. I think they are saying the Theta IO wave in 5C is from a larger population\n- **They simulate a distribution of 1000 neurons with gamma EO freqs with mean 47Hz and SD 2Hz**\n\nThere is a section, sec 7.1, which tries to resolve the issue where individual neurons fire more frequently than the slower population frequency. The resolution they reach is that the Inhib cells are locked to the pop.freq. while excit. neurons have a diverse spread of activity.\n- This is the main thesis but not certain how they arrived at it / what it means\n- \n#### Interval Timing\nFuck I am soooo fucking lost on this one.\nThis is basically all in service of figure 6\nMore or less describing their model / simulation I think\n\n\u003e For example, before any triggering event, both excitatory and inhibitory inputs oscillate at a 6-Hz frequency, cancelling each other out. The onset of a to-be-timed signal and the resulting DA input to the cortical neurons (see Allman and Meck, 2012; Matell and Meck, 2004) triggers a sudden increase of EO frequencies in each neuron while leaving the IO synchronized at a slightly lower frequency than the EO. Depending on the density of synaptic connections or by any other reason of cellular diversity, the excitatory inputs to each individual neuron will oscillate at different frequencies, for example, Neuron 1, 2, 3, and 4 will receive 6.2 Hz, 6.35 Hz, 6.5 Hz and 6.65 Hz of EO input, respectively as illustrated in **Fig. 6A**.\n\n\u003e The summation of EO and IO inputs in each cortical neuron will produce a membrane potential oscillation (MPO) of theta oscillations, enveloped in delta oscillations as previously described. The different frequencies of EO will produce different frequencies of theta MPO, entrained in different delta oscillations. For example, if IO inputs are synchronized at 6 Hz, the MPO of Neuron 1 will show a 6.1-Hz theta oscillation entrained within a 0.2-Hz delta oscillation, whereas Neuron 3 will show a 6.25-Hz theta entrained within a 0.5-Hz delta oscillation as illustrated in **Fig. 6B**.\n\n\u003e After applying a membrane potential threshold for generating spikes, each neuron will show a different pattern of firing rates across time. For example, Neuron 1, whose EO and IO summation produces a theta oscillation entrained within a 0.2-Hz delta oscillation, would show high firing rates of spikes with 0.2 Hz (every 5 s—so at 2.5 s, 7.5 s, 12.5 s, and so on). Similarly, Neuron 3 with a 0.5-Hz delta oscillation would show high firing rates of spikes with 0.5 Hz (every 2 s—so at 1 s, 3 s, 5 s, and so on).\n\n\u003e Under these conditions MSNs in the striatum could be trained to detect the coincident firing of a subset of cortical neurons to encode/detect a specific target duration, as well as strengthening the synaptic weights among the specific MSNs and cortical neurons (as originally proposed by the SBF model). If both of the cortical neurons in our previous example (e.g., Neurons 1 and 3) are strongly connected to a certain group of MSNs, then those MSNs will receive a high firing rate of spikes at approximately 3 s as illustrated in **Fig. 6E**.\n\n\u003e On the other hand, if a different group of MSNs is strongly connected to other cortical neurons whose firing rates peak at 4 s (e.g., Neurons 2 and 4 as illustrated in Fig. 6B), then this group of MSNs will play the role of 4-s detector. In this way, each MSN (or group of MSNs) can detect the coincident firing of multiple cortical subunits, and different MSNs can encode different durations by being connected to a different subset of cortical neurons as illustrated in **Fig. 6E**.\n\nI kinda don’t like how this just “encodes” time by the MSNs just happening to be connected to one or more “oscillator” effectively.\nIt so happens in this example they give two “oscillators” which inform the MSN. Perhaps this would involve multiple?\n- It does say “by being connected to a particular subset”\n- So when those are firing, and a MSN is rewarded, thus pushing it over the firing boundary it STDPs to the subset of EIO which was firing with it\n- \nPerhaps the rescaling is what is important.\n\n\n\u003e [!Figure] Figure 6\n\u003e ![[image-20230622152648112.png]]\n\u003e **(A)** Theta range of EO (blue) and IO (red) inputs to each cortical neuron are balanced before a triggering event (e.g., dopamine input). The timing onset drives the EO inputs to individual cortical neurons oscillate in the faster and various frequencies while IO inputs are synchronized such as in 6 Hz. \n\u003e \n\u003e **(B)** Summation of EO and IO inputs in each neuron generates MPO in theta entrained in delta oscillation. The envelope delta frequency differs by the theta frequency of each individual neuron. \n\u003e \n\u003e For example, larger theta frequency of Neuron 4 produces the faster delta frequencies. Neurons 1 and 3 (Orange) exhibit a peak around 3 s, but not at 4 s; Neurons 2 and 4 (Cyan) exhibit a peak at 4 s, but not at 3 s. Detection of coincident firing of the relevant neuronal groups such as Neurons 2 and 4 will produce the timing of the 4-s target duration. \n\u003e \n\u003e **(C)** **Simulation of theta EO frequencies of 1000 cortical neurons is modeled with a mean of 6.5 Hz and SD of 0.2 Hz while IO frequency is fixed at 6 Hz**. \n\u003e \n\u003e **(D)** **Simulation of total spike inputs from the cortex to the striatum. It shows relatively little spiking between 0 and 0.5 s after the DA input and shows a peak at 0.5–1 s**. \n\u003e \n\u003e **(E)** Spikes to each MSN neuron from the cortex show a peak at the target time of each MSN, but also exhibit fluctuating patterns across time. For example, 3 s MSN receives peak inputs at 3 s, however, the inputs fluctuate and oscillate in time. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)\n\u003e \n\n#### Cell Mechanisms and Simulation Parameters\n\u003e This new EIO model assumes that the frequency of EO varies across neurons, but this varying frequency across neurons is relatively constant given a particular stimulus. \n\u003e \n\u003e The underlying mechanisms of various EO frequencies (and the synchronized IO) should receive further consideration; however, different amounts of recurrent excitatory inputs to each cell or different effects of DA at each neuron or different conductance ratios of neurons could be major factors contributing to the variation in oscillation frequencies (e.g., Gasparini and Magee, 2006; Magee, 2001). \n\n\n\u003e In our simulated model the distribution of EO frequencies is defined as a normal distribution with a mean of 6.5 Hz and a standard deviation of 0.2 Hz as illustrated in **Fig. 6C**. The IO frequency was fixed at 6 Hz for a particular neuronal population, based upon evidence from the previous reports (Geisler et al., 2010; Matell and Meck, 2004).\n\nOk so there was 1000 EO neurons each with a particular freq. which was given by a gaussian distribution around 6.5Hz. See Fig.6c.\n\nDoes this mean there were effective 1-1 IO neurons for each EO?\n\n\n#### Variation / scaling\nIt looks like they propose changing the variance of an “oscillator” by speeding up the firing rate of an individual EO neuron.\n\n\u003e Variation in the EO frequencies will play an important role in encoding various target durations and also a change in the frequency distribution can cause some important behavioral phenomena. For example, if the distribution of EO frequencies is shifted rightwards (increased) without changes in IO, the same firing peak will be reached sooner than the physical time, so that the learned target duration will be reproduced shorter than it should be. As proposed in the SBF model, DA input to the cortex would be able to determine the clock speed by modulating the EO frequencies. However, compared to the SBF model where the whole network should speed up or slow down to same degree, this new model allows for more variation in the oscillation speed of each neuron. Each neuron can speed up by a slightly different amount independently (e.g., the EO frequency of Neuron 2 can change from 6.35 Hz to 6.36 Hz, while the EO frequency of Neuron 4 can remain constant at 6.65 Hz). This would result in an increase in the variability of the behavioral output without seriously disturbing the accuracy of the timing.\n\n#### No cold storage\n\u003e the EIO account does not require a separate accumulator for temporal information, nor does it require a specialized pacemaker providing the temporal information, but it instead derives temporal information from the dynamics of other cognitive components such as the encoding and storage of new information in memory\n\n## Leaving off at section 7.3-ish\n\n# [[21.06.23]]\n Following yesterday \n## I think what I’m getting from all this is:\nThat my experiment, which has no initial stimulus and thus no initial stimulus\n\nIs instead testing for a midscale time interval, where unstimulated reward is to be timed, and is reliant on longer free-associating oscillators, perhaps made of the smaller SBF oscillator collections\n\nIn that we have multiple oscillator circuits that are just freely running as indicative of a larger stable state, and stimulus is mapped directly to their “phase-stamp”\n\nHow would our network state change to represent changes in intervals, as well as multiple intervals?\nIs it possible to entangle the information multiple intervals in a smaller network which does not rely on on single dedicated coincidence detectors for each interval?\n\nOr perhaps populations of MSNs are what react and change (i.e. our chances of acting via weights). I.e. if multiple MSNs are tuned to our “action” instead of “multiple actions each with some MSN”, then the percentage of the population that is tuned to our oscillators, is the “weight” I.e. more MSNs will tune to the “correct” oscillators and will be inhibited to the “wrong ones”.\n\nOr something like that. It may be possible .\n\n## Some writing blurbs\nlol forgot what it was. \n\nIt was a more general introduction: “The SBF is a well supported model…etc….”\n\nOh yeah start writing on how it is more in line with a state-dependent network, and distributes its encodings.\n\nI think I am more interested in how oscillation in the brain are related to one another than strictly just finding “coincidence”. How is a continuous time-mapping created in the brain. Thus, this is sort of moving towards a variant of the SBF.\n\nThe Model does rely on a continuous and plastic mapping, however we are attempting it in a discrete framework\n\n\n## [[@tekiPersistenceMemoryHow2017|Teki et al. (2017)]]\n\u003e **Entorhinal ‘grid cells’ are also probably a source of temporal information for these ‘time cells’  [[65](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6004118/#R65)]** .\n\n### Check [[@buzsakiBrainRhythmsHave2023|Buzsáki and Vöröslakos (2023)]] fo information on the Delta and Theta rhythms\n\u003e Specifically, *the model suggests that duration information can be extracted from theta oscillations entrained in the **delta rhythm** while item information in working memory can be extracted from gamma oscillations entrained in the **theta rhythm** respectively*. Moreover, this proposal is supported by recent electrophysiological studies [45–47]. \n### Citations used for original SBF model\n\u003e 41. Allman MJ, Meck WH. Pathophysiological distortions in time perception and timed performance. Brain. 2012; 135:656–677. [PubMed: 21921020] [• Examines the striatal beat-frequency (SBF) model of interval timing from the point of view of different neurological and psychological conditions (e.g., Parkinson’s disease, schizophrenia, attention deficit hyperactivity disorder, and autism). The review also describes the basics of the SBF model and provides full simulation parameters in the appendix.] \n\n\u003e 42. Lustig C, Matell MS, Meck WH. Not “just” a coincidence: Frontal-striatal synchronization in working memory and interval timing. Memory. 2005; 13:441–448. [PubMed: 15952263] \n\n\u003e 43. Matell MS, Meck WH. Cortico-striatal circuits and interval timing: coincidence detection of oscillatory processes. Cogn Brain Res. 2004; 21(2):139–170.\n\u003e - [[@tekiPersistenceMemoryHow2017|Teki et al. (2017)]]\n\n### Being taken to [[@lismanThetaGammaNeuralCode2013]] for information about “working memory”\n![[Working Memory#Working Memory]]\n\n\n\n\n### [[Excitatory - Inhibitory Oscillation (EIO-SBF)|EIO-SBF]]\nBreaking it down, we have two oscillators of importance: \n- **the Excitatory Oscillator (EO**):\n\t- Per time cell oscillation period\n\t- Resets with stimuli, I think\n- **the Inhibitory Oscillator (IO)**:\n\t- The synchronized to a global (or local) rythm\n\t- So would be the steady lifetime oscillator\n- their resultant interference pattern is what causes the “peaks”\n  \u003e EO and IO will oscillate in beta rhythms and the summation of EO and IO inputs in each neuron will produce an interference pattern of beta entrained in delta or a slower rhythm\n- Why is this required instead of some population of synchronous activity for each time cell oscillator?\n\n**Are Beta Rhythms oscillations in the frequency range of 15-35Hz?**\n\n### Integration of HPC time cells\n\u003e The capacity to support relational memory makes the hippocampus an ideal brain structure for temporal integration [56, 57], as temporal connections are implicitly made between events.\n\n#### TIME CELLS first discovered in reference:\n58. MacDonald CJ, Carrow S, Place R, Eichenbaum H. Distinct hippocampal time cell sequences represent odor memories in immobilized rats. J Neurosci. 2013; 33(36):14607–14616. [PubMed: 24005311]\n\u003e The temporal reference frame in hippocampal ‘time cells’ was first identified in the CA1 pyramidal layer of rats by MacDonald and colleagues [58]. Their findings provided support for the proposal that hippocampal ‘time cells’ signal both temporal and spatial information on a continuum. \n\u003e \n\u003e This was based on the observation that when the duration of a delay period was suddenly changed, largely new sequential patterns of activity emerged. Thus, just as ‘place cells’ remap to represent different spatial contexts, these ‘time cells’ adjusted (what the authors referred to as “retimed”) in order to represent a different temporal context. \n\u003e \n\u003e Consequently, these hippocampal neurons are referred to as ‘time cells’ because they share many of the same general properties of ‘place cells’, but are instead correlated with the temporal domain.\n\n### More about Grid Cells\n![[@tekiPersistenceMemoryHow2017#Grid Cells grid-cells]]\n\n### Fuck I don’t see any actual simulation methods in this \nDidn’t Yin directly say there were?\nGoing back to Yin\n\n## [[@xuTimingIntervalsUsing2016|W. Xu, S.N. Baker (2016)]] Apparently offers another variation but with STDP\n- This appears to use the pacemaker model though\n- nvm they claim to use a “beat-frequency” model\n\n## Reading from [[@yinOscillationCoincidenceDetectionModels2022|Yin et al. (2022)]] again\n\nFrom sec. 3.1:\n\u003e In the discussion of how their beat generation model fits in with other timing models, Bose et al. (2019) described the features of the SBF model that make it distinctive and set it apart from other models of interval timing. In essence, the SBF model uses neuronal oscillators with different fixed frequencies in an unusual way (see Miall, 1989). \n\u003e \n\u003e All the oscillators reset at t = 0; and the differences in the drifting frequencies of convergent units will eventually result in a near-coincidence (the so-called ‘beating phenomenon’ of non-identical oscillators) at a duration that as a result of reinforcement learning (strengthening of synapses onto coincidence-detector units) can match the target duration (Petter et al., 2018). \n\u003e \n\u003e As Bose et al. (2019) note, the uniqueness and applicability of this model have not been lost on others as it has been extended to the periodic case and considered for rhythmic prediction/reproduction by a number of investigators interested in the calculation of rate, time, and numbers due to it offering a more general case than the pacemaker–accumulator account of the phenomena (e.g., Brighouse et al., 2014; Hartcher-O’Brien et al., 2016; Teki et al., 2012 – in addition to Gu et al., 2011).\n\n- Checking out the [[@miallStorageTimeIntervals1989a|C. Miall (1989)]] ref real quick\n\t- Looks like the basis of the entire model\n- Also checked out [[@boseNeuromechanisticModelRhythmic2019|Bose et al. (2019)]] and it does not appear relevant \n## Did I not check [[@guOscillatoryMultiplexingNeural2015a]]\n- Ok I did a long time ago check [[Outline of SBF Model]]\n\t- Goes over the rhythms in depth\n\t- especially the role of Beta Rhythm\n\t- Appears to implicate a beta and gamma entrainment / phase locking\n- This is going places\n- Particularly wants to point out the implication of working memory within the same structures (which ones?)\n\t- Basal Ganglia duh\n\t- But the other papers including Teki  and Yin also want to point out overlaps\n\t\u003e As one of the models explaining neuroanatomical localization of working memory, the prefrontal cortex, basal ganglia working memory (PBWM) model (Frank et al., 2001; Hazy et al., 2006, 2007; O’Reilly and Frank, 2006) suggests a critical role for cortico-striatal circuits in selecting and maintaining relevant information in working memory. The PBWM model explains that PFC actively maintains task-relevant information that is dynamically gated/updated by the basal ganglia. In addition, the posterior cortex and hippocampus play a role in automatic sensory/motor processing and the rapid learning of arbitrary associations, respectively (e.g., Collins and Franck, 2012).\n\t\n\t\u003e The proposed neural mechanisms of the PBWM model share some similarities with the SBF model of interval timing. For example, both rely on the posited involvement of the same brain areas—emphasizing a role for the striatum in detecting/gating cortical inputs. Specifically, the role of the striatum has been suggested as detecting the coincident pattern of cortical inputs in the SBF model and as gating/updating information by integration of cortical input and DA signals in PBWM model.\n\t\n\t\u003e The selected (gated) signals are hypothesized to pass through the thalamus to the cortex in both models and to be modulated by DA (see Hazy et al., 2006, 2007; Matell and Meck, 2004). Also, both models accommodate a role for DA signaling in learning so that the synapses of MSNs in the striatum can be weighted appropriately. In the SBF model, feedback and/or the delivery of reward for responses occurring just after the target duration induces phasic DA input to the striatum which can strengthen the synapses of MSN receiving inputs from the relevant subset of cortical oscillating neurons in order for them to serve as “detectors” for specific target durations (Ullsperger et al., 2014; van Rijn et al., 2014). Similarly, the PBWM model explains that phasic DA input modulates the MSN synapses so that the relevant cortical inputs can trigger the gating/updating of the relevant information. Given these similarities, it has been suggested that interval timing and working memory rely not only on the same gross anatomical structures, but also on the same neural representations (Buhusi and Meck, 2009; Lewis and Miall, 2006; Lustig and Meck, 2005; Lustig et al., 2005).\n\n#### [[@guOscillatoryMultiplexingNeural2015a|Gu et al. (2015)]] on the SBF \nProbably the best anatomical descriptor so far\nMove to the citation page\n\n\u003e Specifically, the SBF model suggests that each cortical neuron oscillates at a preferred oscillatory frequency covering, for example, the alpha and theta frequency bands. With the onset of a stimulus to-be-timed, the phases of multiple oscillators are reset by a burst of dopaminergic input from the ventral tegmental area (VTA).\n\n\u003e Then, these cortical neurons continue to oscillate according to their endogenous oscillatory periods, and their coincident activation pattern can be detected by striatal MSNs during the course of the to-be-timed signal as illustrated in Fig. 2.\n\n\u003e MSN’s have the potential to serve as coincidence detectors because one MSN receives tens of thousands of inputs from divergent cortical and thalamic neurons and needs simultaneous input to be activated (Groves et al., 1995; Wilson, 1995, 1998).\n\n\u003e The synaptic weights between a MSN and cortical neurons with different endogenous oscillatory periods determine for which duration this MSN encodes. Even with drift in the oscillatory periods over time, the synchrony provided by the resetting at the start of a signal is sufficient to maintain a stable encoding of duration.\n\n\u003e The combination of drift on the one hand, and the reliance on slower oscillating cortical neurons for MSNs that encode for longer durations provide a constant coefficient of variation across signal durations in the seconds-to-minutes range and match the level of sensitivity to time observed in humans and other animals (Gibbon et al., 1984, 1997; Matell and Meck, 2004; Penney et al., 2008).\n\n\u003e According to this account, the learning of a new target duration can be explained within the same cortico-striatal circuit by modulating synaptic weights among MSNs and subsets of cortical neurons. For example, if the learning of a 6-s target duration has induced a MSN to be highly connected with a subset of cortical neurons whose firing rates are maximal 6 s after signal onset, the learning of a 10-s target duration will induce a different set of synaptic weights to a MSN as a result of stronger connections with a subset of cortical neurons that fire more frequently around 10 s.\n\n\u003e Phasic DA release into the striatum from the SNc is hypothesized to serve as the reinforcement signal for learning of new target durations, thus allowing modulation of the MSN synaptic weights and new learning (Agostino et al., 2011; MacDonald et al., 2012; Matell and Meck, 2004).\n- #dopamine #reinforcement #rl\n\n\u003e The strength of the SBF model lies in its specification of known neural mechanisms, as well as its consistency with the available anatomical, behavioral, and pharmacological evidence (Allman and Meck, 2012; Coull et al., 2011; Merchant et al., 2013a). MSNs in the striatum have the appropriate characteristics to serve as a largescale coincidence-detector system because they receive a great deal of convergent, multi-modal input from the cortex (Wilson, 1995, 1998) and such coincident excitatory input from the cortex can drive the MSNs into the “Up state” (O’Donnell and Grace, 1995; Wilson, 1993).\n\nLists inhibition and lesion induced experiments if I need that. Also other evidence.\n\n##### Variance\n\u003e It has been suggested, however, that this model can be susceptible to the variance of the oscillation periods. If the cortical oscillators are independent of each other so that they have different variations in their oscillation period, the ability of representing detectable coincident patterns will be significantly impaired even with a small amount of variance if they aren’t reset properly. \n\u003e \n\u003e The variance in oscillation period (i.e., variability in clock speed) that the model allows under this condition are quite small, i.e., less than 3% of the period, and considering that the variance can accumulate with time, the detection of longer durations in the minutes range could be much more debilitated. \n\u003e \n\u003e However, if the variance is introduced globally (e.g., all oscillation periods are increased by 4%), the models’ detection ability is not affected, but only the overall clock speed will be changed (see Oprisan and Buhusi, 2011, 2013, 2014)\n- what does overall clock speed change mean?\n\n\u003e Therefore, additional coupling mechanisms for cortical oscillators that can reduce the independence of oscillating neurons with different frequencies be investigated in order to incorporate a more biologically plausible level of variance into the system while still allowing for independence of multiple timing processes (Buhusi and Meck, 2009b)\n\n\n\n# [[20.06.23]]\n## Picking back up from yesterday\n### Reading [[@hardyNeurocomputationalModelsInterval2016]]\n\n## Also it appears that the Mosers have a similar paper\n[[@tsaoNeuralBasesTiming2022]]\nThat references GM\n[The neural bases for timing of durations | Nature Reviews Neuroscience](https://www.nature.com/articles/s41583-022-00623-3)\nUnfortunately,  I can’t find a copy\n\n## I want to know how they were simulated [[@tekiPersistenceMemoryHow2017]]\n\n## Other reading I want:\n[[@tekiPersistenceMemoryHow2017]]\n[[@xuTimingIntervalsUsing2016|Xu and Baker (2016)]]\n\n## [[@buzsakiBrainRhythmsHave2023]]\n- Why neuronal oscillations are important to begin with\n- Relating moments of integration to neuronal oscillatory cycles can effectively delineate circuits which are separated in time but still feed to the same downstream neuron\n\t- I.e. The informational content of the readout of a neuron can be drastically different depending on the temporal context\n- **Mention that oscillations are built on inhibition**\n\t- **So using the zeroth-oscillator as an inhibitory circuit**\n- I want to use a timing model that builds on oscillations\n\n## Maybe use a power-law distribution for the oscillators? #dev\nBecause they mention adding “***1/f Noise***” somewhere. find that.\n\nSo for closer to RP p(x=RP)  = low, x is the oscillator size. Thus P(RP) = 0, because we never want to get it exactly.\n\nNeed to be able to set the minimum and the max = RP\n\n\n### In Python\n[numpy.random.power — NumPy v1.25 Manual](https://numpy.org/doc/stable/reference/random/generated/numpy.random.power.html)\nFrom [scipy.stats.powerlaw — SciPy v1.10.1 Manual](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.powerlaw.html):\n\u003e The probability density function for powerlaw is:\n\u003e $$\n\u003e f(x, a)=a x^{a-1}\n\u003e $$\n\u003e for $0 \\leq x \\leq 1, a\u003e0$\n\u003e powerlaw takes a as a shape parameter for $a$.\n\u003e The probability density above is defined in the “standardized” form. To shift and/or scale the distribution use the `loc` and `scale` parameters. Specifically, `powerlaw.pdf(x, a, loc, scale)` is identically equivalent to `powerlaw.pdf(y, a) / scale` with `y = (x - loc) / scale`. Note that shifting the location of a distribution does not make it a “noncentral” distribution; noncentral generalizations of some distributions are available in separate classes.\n\u003e \n\u003e For example, the support of [`powerlaw`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.powerlaw.html#scipy.stats.powerlaw \"scipy.stats.powerlaw\") can be adjusted from the default interval `[0, 1]` to the interval `[c, c+d]` by setting `loc=c` and `scale=d`. For a power-law distribution with infinite support, see [`pareto`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pareto.html#scipy.stats.pareto \"scipy.stats.pareto\").\n\u003e \n### Mathematically:\n[random generation - Accurately generating variates from discrete power law distribution - Cross Validated](https://stats.stackexchange.com/questions/88496/accurately-generating-variates-from-discrete-power-law-distribution)\n[Sampling distribution of the mean of the discrete-power law distribution - Cross Validated](https://stats.stackexchange.com/questions/475566/sampling-distribution-of-the-mean-of-the-discrete-power-law-distribution)\n\n\n[ON THE POWER LAW STATISTICAL DISTRIBUTION OF OBSERVATIONS](https://indico.ictp.it/event/a08182/session/44/contribution/28/material/0/0.pdf)\n![[image-20230621192809301.png]]\n\n\n![[image-20230621193405516.png]]\n\n\n\n## Cold Storage\n- Most models rely on a cold storage or the “saving to memory slots” of information, memory, and episodes. \n- Even assuming some dedicated memory circuit, these must be used to store multiple memory states, and not just one\n- Instead memory is distributed across the state of a network or circuit\n\nSee [[@tekiPersistenceMemoryHow2017|Teki et al. (2017)]] ***Models of Working Memory*** Section\n\n## [[Working Memory]]\n\u003e Working memory is traditionally defined as a cognitive capacity for transiently storing, processing, and manipulating information.\n\u003e - [[@tekiPersistenceMemoryHow2017]]\n\n\n# [[19.06.23]]\n## Extractions from reading\n\u003e Hardy \u0026 Buonomano (2016) have recently proposed that the brain encodes time in dynamic patterns of neural activity that are referred to as population clocks.\n- So find out what is meant by that\n\n# [[17.06.23]]\nCatching up on SBFA writing\nOk so yesterday I found a bunch of research I was previously doing that I thought was relevant\n\nI left off at [[The Persistence of Memory How the Brain Encodes Time in Memory - 21.11.22.md]] and [[@tekiPersistenceMemoryHow2017]]. This is the one that introduces EIO-SBF\n\n\nI think I started at finding the old outlines I made of the SBF [[Outline of SBF Model]] and [[Outline of SBF Model for Supervision Meeting]] which have a bit of detail and can absolutely be used for part of my writing.\n\nBut from there I migrated and rediscovered much of the SBF papers that must be referenced.\n\nGustavos paper must be included [[@melloNeuralBehavioralMechanisms2016]]\n\n\n# [[12.06.23]]\n[[Outline 2.0]]\n\n[^1]: ","lastmodified":"2023-07-25T13:18:04.759882876Z","tags":[]},"/notes/callouts":{"title":"Callouts","content":"\n## Callout support\n\nQuartz supports the same Admonition-callout syntax as Obsidian.\n\nThis includes\n- 12 Distinct callout types (each with several aliases)\n- Collapsable callouts\n\nSee [documentation on supported types and syntax here](https://help.obsidian.md/Editing+and+formatting/Callouts).\n\n## Showcase\n\n\u003e [!EXAMPLE] Examples\n\u003e\n\u003e Aliases: example\n\n\u003e [!note] Notes\n\u003e\n\u003e Aliases: note\n\n\u003e [!abstract] Summaries \n\u003e\n\u003e Aliases: abstract, summary, tldr\n\n\u003e [!info] Info \n\u003e\n\u003e Aliases: info, todo\n\n\u003e [!tip] Hint \n\u003e\n\u003e Aliases: tip, hint, important\n\n\u003e [!success] Success \n\u003e\n\u003e Aliases: success, check, done\n\n\u003e [!question] Question \n\u003e\n\u003e Aliases: question, help, faq\n\n\u003e [!warning] Warning \n\u003e\n\u003e Aliases: warning, caution, attention\n\n\u003e [!failure] Failure \n\u003e\n\u003e Aliases: failure, fail, missing\n\n\u003e [!danger] Error\n\u003e\n\u003e Aliases: danger, error\n\n\u003e [!bug] Bug\n\u003e\n\u003e Aliases: bug\n\n\u003e [!quote] Quote\n\u003e\n\u003e Aliases: quote, cite\n","lastmodified":"2023-07-25T13:18:04.759882876Z","tags":[]},"/notes/config":{"title":"Configuration","content":"\n## Configuration\nQuartz is designed to be extremely configurable. You can find the bulk of the configuration scattered throughout the repository depending on how in-depth you'd like to get.\n\nThe majority of configuration can be found under `data/config.yaml`. An annotated example configuration is shown below.\n\n```yaml {title=\"data/config.yaml\"}\n# The name to display in the footer\nname: Jacky Zhao\n\n# whether to globally show the table of contents on each page\n# this can be turned off on a per-page basis by adding this to the\n# front-matter of that note\nenableToc: true\n\n# whether to by-default open or close the table of contents on each page\nopenToc: false\n\n# whether to display on-hover link preview cards\nenableLinkPreview: true\n\n# whether to render titles for code blocks\nenableCodeBlockTitle: true \n\n# whether to render copy buttons for code blocks\nenableCodeBlockCopy: true \n\n# whether to render callouts\nenableCallouts: true\n\n# whether to try to process Latex\nenableLatex: true\n\n# whether to enable single-page-app style rendering\n# this prevents flashes of unstyled content and improves\n# smoothness of Quartz. More info in issue #109 on GitHub\nenableSPA: true\n\n# whether to render a footer\nenableFooter: true\n\n# whether backlinks of pages should show the context in which\n# they were mentioned\nenableContextualBacklinks: true\n\n# whether to show a section of recent notes on the home page\nenableRecentNotes: false\n\n# whether to display an 'edit' button next to the last edited field\n# that links to github\nenableGitHubEdit: true\nGitHubLink: https://github.com/jackyzha0/quartz/tree/hugo/content\n\n# whether to render mermaid diagrams\nenableMermaid: true\n\n# whether to use Operand to power semantic search\n# IMPORTANT: replace this API key with your own if you plan on using\n# Operand search!\nsearch:\n  enableSemanticSearch: false\n  operandApiKey: \"REPLACE-WITH-YOUR-OPERAND-API-KEY\"\n  operandIndexId: \"REPLACE-WITH-YOUR-OPERAND-INDEX-ID\"\n\n# page description used for SEO\ndescription:\n  Host your second brain and digital garden for free. Quartz features extremely fast full-text search,\n  Wikilink support, backlinks, local graph, tags, and link previews.\n\n# title of the home page (also for SEO)\npage_title:\n  \"🪴 Quartz 3.3\"\n\n# links to show in the footer\nlinks:\n  - link_name: Twitter\n    link: https://twitter.com/_jzhao\n  - link_name: Github\n    link: https://github.com/jackyzha0\n```\n\n### Code Block Titles\nTo add code block titles with Quartz:\n\n1. Ensure that code block titles are enabled in Quartz's configuration:\n\n    ```yaml {title=\"data/config.yaml\", linenos=false}\n    enableCodeBlockTitle: true\n    ```\n\n2. Add the `title` attribute to the desired [code block\n   fence](https://gohugo.io/content-management/syntax-highlighting/#highlighting-in-code-fences):\n\n      ```markdown {linenos=false}\n       ```yaml {title=\"data/config.yaml\"}\n       enableCodeBlockTitle: true  # example from step 1\n       ```\n      ```\n\n**Note** that if `{title=\u003cmy-title\u003e}` is included, and code block titles are not\nenabled, no errors will occur, and the title attribute will be ignored.\n\n### HTML Favicons\nIf you would like to customize the favicons of your Quartz-based website, you \ncan add them to the `data/config.yaml` file. The **default** without any set \n`favicon` key is:\n\n```html {title=\"layouts/partials/head.html\", linenostart=15}\n\u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n```\n\nThe default can be overridden by defining a value to the `favicon` key in your \n`data/config.yaml` file. For example, here is a `List[Dictionary]` example format, which is\nequivalent to the default:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon:\n  - { rel: \"shortcut icon\", href: \"icon.png\", type: \"image/png\" }\n#  - { ... } # Repeat for each additional favicon you want to add\n```\n\nIn this format, the keys are identical to their HTML representations.\n\nIf you plan to add multiple favicons generated by a website (see list below), it\nmay be easier to define it as HTML. Here is an example which appends the \n**Apple touch icon** to Quartz's default favicon:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon: |\n  \u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n  \u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"\u003e\n```\n\nThis second favicon will now be used as a web page icon when someone adds your \nwebpage to the home screen of their Apple device. If you are interested in more \ninformation about the current and past standards of favicons, you can read \n[this article](https://www.emergeinteractive.com/insights/detail/the-essentials-of-favicons/).\n\n**Note** that all generated favicon paths, defined by the `href` \nattribute, are relative to the `static/` directory.\n\n### Graph View\nTo customize the Interactive Graph view, you can poke around `data/graphConfig.yaml`.\n\n```yaml {title=\"data/graphConfig.yaml\"}\n# if true, a Global Graph will be shown on home page with full width, no backlink.\n# A different set of Local Graphs will be shown on sub pages.\n# if false, Local Graph will be default on every page as usual\nenableGlobalGraph: false\n\n### Local Graph ###\nlocalGraph:\n    # whether automatically generate a legend\n    enableLegend: false\n    \n    # whether to allow dragging nodes in the graph\n    enableDrag: true\n    \n    # whether to allow zooming and panning the graph\n    enableZoom: true\n    \n    # how many neighbours of the current node to show (-1 is all nodes)\n    depth: 1\n    \n    # initial zoom factor of the graph\n    scale: 1.2\n    \n    # how strongly nodes should repel each other\n    repelForce: 2\n\n    # how strongly should nodes be attracted to the center of gravity\n    centerForce: 1\n\n    # what the default link length should be\n    linkDistance: 1\n    \n    # how big the node labels should be\n    fontSize: 0.6\n    \n    # scale at which to start fading the labes on nodes\n    opacityScale: 3\n\n### Global Graph ###\nglobalGraph:\n\t# same settings as above\n\n### For all graphs ###\n# colour specific nodes path off of their path\npaths:\n  - /moc: \"#4388cc\"\n```\n\n\n## Styling\nWant to go even more in-depth? You can add custom CSS styling and change existing colours through editing `assets/styles/custom.scss`. If you'd like to target specific parts of the site, you can add ids and classes to the HTML partials in `/layouts/partials`. \n\n### Partials\nPartials are what dictate what gets rendered to the page. Want to change how pages are styled and structured? You can edit the appropriate layout in `/layouts`.\n\nFor example, the structure of the home page can be edited through `/layouts/index.html`. To customize the footer, you can edit `/layouts/partials/footer.html`\n\nMore info about partials on [Hugo's website.](https://gohugo.io/templates/partials/)\n\nStill having problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n\n## Language Support\n[CJK + Latex Support (测试)](notes/CJK%20+%20Latex%20Support%20(测试).md) comes out of the box with Quartz.\n\nWant to support languages that read from right-to-left (like Arabic)? Hugo (and by proxy, Quartz) supports this natively.\n\nFollow the steps [Hugo provides here](https://gohugo.io/content-management/multilingual/#configure-languages) and modify your `config.toml`\n\nFor example:\n\n```toml\ndefaultContentLanguage = 'ar'\n[languages]\n  [languages.ar]\n    languagedirection = 'rtl'\n    title = 'مدونتي'\n    weight = 1\n```\n","lastmodified":"2023-07-25T13:18:04.759882876Z","tags":["setup"]},"/notes/custom-Domain":{"title":"Custom Domain","content":"\n### Registrar\nThis step is only applicable if you are using a **custom domain**! If you are using a `\u003cYOUR-USERNAME\u003e.github.io` domain, you can skip this step.\n\nFor this last bit to take effect, you also need to create a CNAME record with the DNS provider you register your domain with (i.e. NameCheap, Google Domains).\n\nGitHub has some [documentation on this](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site), but the tldr; is to\n\n1. Go to your forked repository (`github.com/\u003cYOUR-GITHUB-USERNAME\u003e/quartz`) settings page and go to the Pages tab. Under \"Custom domain\", type your custom domain, then click **Save**.\n2. Go to your DNS Provider and create a CNAME record that points from your domain to `\u003cYOUR-GITHUB-USERNAME.github.io.` (yes, with the trailing period).\n\n\t![Example Configuration for Quartz](/notes/images/google-domains.png)*Example Configuration for Quartz*\n3. Wait 30 minutes to an hour for the network changes to kick in.\n4. Done!","lastmodified":"2023-07-25T13:18:04.759882876Z","tags":[]},"/notes/docker":{"title":"Hosting with Docker","content":"\nIf you want to host Quartz on a machine without using a webpage hosting service, it may be easier to [install Docker Compose](https://docs.docker.com/compose/install/) and follow the instructions below than to [install Quartz's dependencies manually](notes/preview%20changes.md).\n## Hosting Quartz Locally\nYou can serve Quartz locally at `http://localhost:1313` with the following script, replacing `/path/to/quartz` with the \nactual path to your Quartz folder.\n\ndocker-compose.yml\n```\nservices:\n  quartz-hugo:\n    image: ghcr.io/jackyzha0/quartz:hugo\n    container_name: quartz-hugo\n    volumes:\n      - /path/to/quartz:/quartz\n    ports:\n      - 1313:1313\n\n    # optional\n    environment:\n      - HUGO_BIND=0.0.0.0\n      - HUGO_BASEURL=http://localhost\n      - HUGO_PORT=1313\n      - HUGO_APPENDPORT=true\n      - HUGO_LIVERELOADPORT=-1\n```\n\nThen run with: `docker-compose up -d` in the same directory as your `docker-compose.yml` file.\n\nWhile the container is running, you can update the `quartz` fork with: `docker exec -it quartz-hugo make update`.\n\n## Exposing Your Container to the Internet\n\n### To Your Public IP Address with Port Forwarding (insecure)\n\nAssuming you are already familiar with [port forwarding](https://en.wikipedia.org/wiki/Port_forwarding) and [setting it up with your router model](https://portforward.com):\n\n1. You should set the environment variable `HUGO_BASEURL=http://your-public-ip` and then start your container.\n2. Set up port forwarding on your router from port `p` to `your-local-ip:1313`.\n3. You should now be able to access Quartz from outside your local network at `http://your-public-ip:p`.\n\nHowever, your HTTP connection will be unencrypted and **this method is not secure**.\n\n### To a Domain using Cloudflare Proxy\n\n1. Port forward 443 (HTTPS) from your machine.\n2. Buy a custom domain (say, `your-domain.com`) from [Cloudflare](https://www.cloudflare.com/products/registrar/). Point a DNS A record from `your-domain.com` to your public IP address and enable the proxy.\n3. Set the environment variables `HUGO_BASEURL=https://your-domain.com`, `HUGO_PORT=443`, and `HUGO_APPENDPORT=false`. Change `1313:1313` to `443:443` for the `ports` in `docker-compose.yml`.\n4. Spin up your Quartz container and enjoy it at `https://your-domain.com`!\n\n### To a Domain using a Reverse Proxy\n\nIf you want to serve more than just Quartz to the internet on this machine (or don't want to use the Cloudflare registrar and proxy), you should follow the steps in the section above (as appropriate) and also set up a reverse proxy, like [Traefik](https://doc.traefik.io/traefik). Be sure to configure your TLS certificates too!\n","lastmodified":"2023-07-25T13:18:04.759882876Z","tags":["setup"]},"/notes/editing":{"title":"Editing Content in Quartz","content":"\n## Editing \nQuartz runs on top of [Hugo](https://gohugo.io/) so all notes are written in [Markdown](https://www.markdownguide.org/getting-started/).\n\n### Folder Structure\nHere's a rough overview of what's what.\n\n**All content in your garden can found in the `/content` folder.** To make edits, you can open any of the files and make changes directly and save it. You can organize content into any folder you'd like.\n\n**To edit the main home page, open `/content/_index.md`.**\n\n### Front Matter\nHugo is picky when it comes to metadata for files. Make sure that your title is double-quoted and that you have a title defined at the top of your file like so, otherwise the generated page will not have a title!\n\nYou can also add tags here as well.\n\n```yaml\n---\ntitle: \"Example Title\"\ntags:\n- example-tag\n---\n\nRest of your content here...\n```\n\n### Obsidian\nI recommend using [Obsidian](http://obsidian.md/) as a way to edit and grow your digital garden. It comes with a really nice editor and graphical interface to preview all of your local files.\n\nThis step is **highly recommended**.\n\n\u003e 🔗 Step 3: [How to setup your Obsidian Vault to work with Quartz](notes/obsidian.md)\n\n## Previewing Changes\nThis step is purely optional and mostly for those who want to see the published version of their digital garden locally before opening it up to the internet. This is *highly recommended* but not required.\n\n\u003e 👀 Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n\nFor those who like to live life more on the edge, viewing the garden through Obsidian gets you pretty close to the real thing.\n\n## Publishing Changes\nNow that you know the basics of managing your digital garden using Quartz, you can publish it to the internet!\n\n\u003e 🌍 Step 5: [Hosting Quartz online!](notes/hosting.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-07-25T13:18:04.759882876Z","tags":["setup"]},"/notes/hosting":{"title":"Deploying Quartz to the Web","content":"\n## Hosting on GitHub Pages\nQuartz is designed to be effortless to deploy. If you forked and cloned Quartz directly from the repository, everything should already be good to go! Follow the steps below.\n\n### Enable GitHub Actions Permissions\nBy default, GitHub disables workflows from modifying your files (for good reason!). However, Quartz needs this to write the actual site files back to GitHub.\n\nHead to `Settings \u003e Action \u003e General \u003e Workflow Permissions` and choose `Read and Write Permissions`\n\n![[notes/images/github-actions.png]]\n*Enable GitHub Actions*\n\n### Enable GitHub Pages\n\nHead to the 'Settings' tab of your forked repository and go to the 'Pages' tab.\n\n1. (IMPORTANT) Set the source to deploy from `master` (and not `hugo`) using `/ (root)`\n2. Set a custom domain here if you have one!\n\n![Enable GitHub Pages](/notes/images/github-pages.png)*Enable GitHub Pages*\n\n### Pushing Changes\nTo see your changes on the internet, we need to push it them to GitHub. Quartz is a `git` repository so updating it is the same workflow as you would follow as if it were just a regular software project.\n\n```shell\n# Navigate to Quartz folder\ncd \u003cpath-to-quartz\u003e\n\n# Commit all changes\ngit add .\ngit commit -m \"message describing changes\"\n\n# Push to GitHub to update site\ngit push origin hugo\n```\n\nNote: we specifically push to the `hugo` branch here. Our GitHub action automatically runs everytime a push to is detected to that branch and then updates the `master` branch for redeployment.\n\n### Setting up the Site\nNow let's get this site up and running. Never hosted a site before? No problem. Have a fancy custom domain you already own or want to subdomain your Quartz? That's easy too.\n\nHere, we take advantage of GitHub's free page hosting to deploy our site. Change `baseURL` in `/config.toml`. \n\nMake sure that your `baseURL` has a trailing `/`!\n\n[Reference `config.toml` here](https://github.com/jackyzha0/quartz/blob/hugo/config.toml)\n\n```toml\nbaseURL = \"https://\u003cYOUR-DOMAIN\u003e/\"\n```\n\nIf you are using this under a subdomain (e.g. `\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz`), include the trailing `/`. **You need to do this especially if you are using GitHub!**\n\n```toml\nbaseURL = \"https://\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz/\"\n```\n\nChange `cname` in `/.github/workflows/deploy.yaml`. Again, if you don't have a custom domain to use, you can use `\u003cYOUR-USERNAME\u003e.github.io`.\n\nPlease note that the `cname` field should *not* have any path `e.g. end with /quartz` or have a trailing `/`.\n\n[Reference `deploy.yaml` here](https://github.com/jackyzha0/quartz/blob/hugo/.github/workflows/deploy.yaml)\n\n```yaml {title=\".github/workflows/deploy.yaml\"}\n- name: Deploy  \n  uses: peaceiris/actions-gh-pages@v3  \n  with:  \n\tgithub_token: ${{ secrets.GITHUB_TOKEN }} # this can stay as is, GitHub fills this in for us!\n\tpublish_dir: ./public  \n\tpublish_branch: master\n\tcname: \u003cYOUR-DOMAIN\u003e\n```\n\nHave a custom domain? [Learn how to set it up with Quartz ](notes/custom%20Domain.md).\n\n### Ignoring Files\nOnly want to publish a subset of all of your notes? Don't worry, Quartz makes this a simple two-step process.\n\n❌ [Excluding pages from being published](notes/ignore%20notes.md)\n\n## Docker Support\nIf you don't want to use a hosting service, you can host using [Docker](notes/docker.md) instead!\nI would *not use this method* unless you know what you are doing.\n\n---\n\nNow that your Quartz is live, let's figure out how to make Quartz really *yours*!\n\n\u003e Step 6: 🎨 [Customizing Quartz](notes/config.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-07-25T13:18:04.759882876Z","tags":["setup"]},"/notes/ignore-notes":{"title":"Ignoring Notes","content":"\n### Quartz Ignore\nEdit `ignoreFiles` in `config.toml` to include paths you'd like to exclude from being rendered.\n\n```toml\n...\nignoreFiles = [  \n    \"/content/templates/*\",  \n    \"/content/private/*\", \n    \"\u003cyour path here\u003e\"\n]\n```\n\n`ignoreFiles` supports the use of Regular Expressions (RegEx) so you can ignore patterns as well (e.g. ignoring all `.png`s by doing `\\\\.png$`).\nTo ignore a specific file, you can also add the tag `draft: true` to the frontmatter of a note.\n\n```markdown\n---\ntitle: Some Private Note\ndraft: true\n---\n...\n```\n\nMore details in [Hugo's documentation](https://gohugo.io/getting-started/configuration/#ignore-content-and-data-files-when-rendering).\n\n### Global Ignore\nHowever, just adding to the `ignoreFiles` will only prevent the page from being access through Quartz. If you want to prevent the file from being pushed to GitHub (for example if you have a public repository), you need to also add the path to the `.gitignore` file at the root of the repository.","lastmodified":"2023-07-25T13:18:04.759882876Z","tags":[]},"/notes/obsidian":{"title":"Obsidian Vault Integration","content":"\n## Setup\nObsidian is the preferred way to use Quartz. You can either create a new Obsidian Vault or link one that your already have.\n\n### New Vault\nIf you don't have an existing Vault, [download Obsidian](https://obsidian.md/) and create a new Vault in the `/content` folder that you created and cloned during the [setup](notes/setup.md) step.\n\n### Linking an existing Vault\nThe easiest way to use an existing Vault is to copy all of your files (directory and hierarchies intact) into the `/content` folder.\n\n## Settings\nGreat, now that you have your Obsidian linked to your Quartz, let's fix some settings so that they play well.\n\nOpen Settings \u003e Files \u0026 Links and look for these two items:\n\n1. Set the **New link format** to **Absolute Path in vault**. If you have a completely flat vault (no folders), this step isn't necessary.\n2. Turn **on** the **Automatically update internal links** setting.\n\n\n![[notes/images/obsidian-settings.png]]*Obsidian Settings*\n\n## Templates\nInserting front matter everytime you want to create a new Note gets annoying really quickly. Luckily, Obsidian supports templates which makes inserting new content really easily.\n\n\u003e [!WARNING]\n\u003e \n\u003e **If you decide to overwrite the `/content` folder completely, don't remove the `/content/templates` folder!**\n\nHead over to Options \u003e Core Plugins and enable the Templates plugin. Then go to Options \u003e Hotkeys and set a hotkey for 'Insert Template' (I recommend `[cmd]+T`). That way, when you create a new note, you can just press the hotkey for a new template and be ready to go!\n\n\u003e 👀 Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n","lastmodified":"2023-07-25T13:18:04.76388289Z","tags":["setup"]},"/notes/philosophy":{"title":"Quartz Philosophy","content":"\n\u003e “[One] who works with the door open gets all kinds of interruptions, but [they] also occasionally gets clues as to what the world is and what might be important.” — Richard Hamming\n\n## Why Quartz?\nHosting a public digital garden isn't easy. There are an overwhelming number of tutorials, resources, and guides for tools like [Notion](https://www.notion.so/), [Roam](https://roamresearch.com/), and [Obsidian](https://obsidian.md/), yet none of them have super easy to use *free* tools to publish that garden to the world.\n\nI've personally found that\n1. It's nice to access notes from anywhere\n2. Having a public digital garden invites open conversations\n3. It makes keeping personal notes and knowledge *playful and fun*\n\nI was really inspired by [Bianca](https://garden.bianca.digital/) and [Joel](https://joelhooks.com/digital-garden)'s digital gardens and wanted to try making my own.\n\n**The goal of Quartz is to make hosting your own public digital garden free and simple.** You don't even need your own website. Quartz does all of that for you and gives your own little corner of the internet.\n","lastmodified":"2023-07-25T13:18:04.76388289Z","tags":[]},"/notes/preview-changes":{"title":"Preview Changes","content":"\nIf you'd like to preview what your Quartz site looks like before deploying it to the internet, the following\ninstructions guide you through installing the proper dependencies to run it locally.\n\n\n## Install `hugo-obsidian`\nThis step will generate the list of backlinks for Hugo to parse. Ensure you have [Go](https://golang.org/doc/install) (\u003e= 1.16) installed.\n\n```bash\n# Install and link `hugo-obsidian` locally\ngo install github.com/jackyzha0/hugo-obsidian@latest\n```\n\nIf you are running into an error saying that `command not found: hugo-obsidian`, make sure you set your `GOPATH` correctly (see [[notes/troubleshooting#`command not found: hugo-obsidian`|the troubleshooting page]])! This will allow your terminal to correctly recognize hugo-obsidian as an executable.\n\n##  Installing Hugo\nHugo is the static site generator that powers Quartz. [Install Hugo with \"extended\" Sass/SCSS version](https://gohugo.io/getting-started/installing/) first. Then,\n\n```bash\n# Navigate to your local Quartz folder\ncd \u003clocation-of-your-local-quartz\u003e\n\n# Start local server\nmake serve\n\n# View your site in a browser at http://localhost:1313/\n```\n\n\u003e [!INFO] Docker Support\n\u003e\n\u003e If you have the Docker CLI installed already, you can avoid installing `hugo-obsidian` and `hugo`. Instead, open your terminal, navigate to your folder with Quartz and run `make docker`\n\nAfterwards, start the Hugo server as shown above and your local backlinks and interactive graph should be populated! Now, let's get it hosted online.\n\n\u003e 🌍 Step 5: [Hosting Quartz online!](notes/hosting.md)\n","lastmodified":"2023-07-25T13:18:04.76388289Z","tags":["setup"]},"/notes/search":{"title":"Search","content":"\nQuartz supports two modes of searching through content.\n\n## Full-text\nFull-text search is the default in Quartz. It produces results that *exactly* match the search query. This is easier to setup but usually produces lower quality matches.\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nenableSemanticSearch: false\n```\n\n## Natural Language\nNatural language search is powered by [Operand](https://beta.operand.ai/). It understands language like a person does and finds results that best match user intent. In this sense, it is closer to how Google Search works.\n\nNatural language search tends to produce higher quality results than full-text search.\n\nHere's how to set it up.\n\n1. Login or Register for a new Operand account. Click the verification link sent to your email, and you'll be redirected to the dashboard. (Note) You do not need to enter a credit card to create an account, or get started with the Operand API. The first $10 of usage each month is free. To learn more, see pricing. If you go over your free quota, we'll (politely) reach out and ask you to configure billing.\n2. Create your first index. On the dashboard, under \"Indexes\", enter the name and description of your index, and click \"Create Index\". Note down the ID of the index (obtained by clicking on the index name in the list of indexes), as you'll need it in the next step. IDs are unique to each index, and look something like `uqv1duxxbdxu`.\n3. Click into the index you've created. Under \"Index Something\", select \"SITEMAP\" from the dropdown and click \"Add Source\".\n4. For the \"Sitemap.xml URL\", put your deployed site's base URL followed by `sitemap.xml`. For example, for `quartz.jzhao.xyz`, put `https://quartz.jzhao.xyz/sitemap.xml`. Leave the URL Regex empty. \n5. Get your API key. On the dashboard, under \"API Keys\", you can manage your API keys. If you don't already have an API key, click \"Create API Key\". You'll need this for the next step.\n6. Open `data/config.yaml`. Set `enableSemanticSearch` to `true`, `operandApiKey` to your copied key, and `operandIndexId` to the ID of the index we created from earlier..\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nsearch:\n  enableSemanticSearch: true\n  operandApiKey: \"jp9k5hudse2a828z98kxd6z3payi8u90rnjf\"\n  operandIndexId: \"s0kf3bd6tldw\"\n```\n7. Push your changes to the site and wait for it to deploy.\n8. Check the Operand dashboard and wait for your site to index. Enjoy natural language search powered by Operand!\n","lastmodified":"2023-07-25T13:18:04.76388289Z","tags":[]},"/notes/setup":{"title":"Setup","content":"\n## Making your own Quartz\nSetting up Quartz requires a basic understanding of `git`. If you are unfamiliar, [this resource](https://resources.nwplus.io/2-beginner/how-to-git-github.html) is a great place to start!\n\n### Forking\n\u003e A fork is a copy of a repository. Forking a repository allows you to freely experiment with changes without affecting the original project.\n\nNavigate to the GitHub repository for the Quartz project:\n\n📁 [Quartz Repository](https://github.com/jackyzha0/quartz)\n\nThen, Fork the repository into your own GitHub account. **Make sure that when you fork, you _uncheck_ the 'Copy the `hugo` branch only' option**.\n\nIf you don't have an account, you can make on for free [here](https://github.com/join). More details about forking a repo can be found on [GitHub's documentation](https://docs.github.com/en/get-started/quickstart/fork-a-repo).\n\n![[notes/images/fork.png]]\n\n### Cloning\nAfter you've made a fork of the repository, you need to download the files locally onto your machine. Ensure you have `git`, then type the following command in your terminal replacing `YOUR-USERNAME` with your GitHub username.\n\n```shell\ngit clone https://github.com/YOUR-USERNAME/quartz\n```\n\n## Editing\nGreat! Now you have everything you need to start editing and growing your digital garden. If you're ready to start writing content already, check out the recommended flow for editing notes in Quartz.\n\n\u003e ✏️ Step 2: [Editing Notes in Quartz](notes/editing.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-07-25T13:18:04.76388289Z","tags":["setup"]},"/notes/showcase":{"title":"Showcase","content":"\nWant to see what Quartz can do? Here are some cool community gardens :)\n\n- [Quartz Documentation (this site!)](https://quartz.jzhao.xyz/)\n- [Jacky Zhao's Garden](https://jzhao.xyz/)\n- [Scaling Synthesis - A hypertext research notebook](https://scalingsynthesis.com/)\n- [AWAGMI Intern Notes](https://notes.awagmi.xyz/)\n- [Shihyu's PKM](https://shihyuho.github.io/pkm/)\n- [SlRvb's Site](https://slrvb.github.io/Site/)\n- [Course notes for Information Technology Advanced Theory](https://a2itnotes.github.io/quartz/)\n- [Brandon Boswell's Garden](https://brandonkboswell.com)\n- [Siyang's Courtyard](https://siyangsun.github.io/courtyard/)\n- [Data Dictionary 🧠](https://glossary.airbyte.com/)\n- [sspaeti.com's Second Brain](https://brain.sspaeti.com/)\n- [oldwinterの数字花园](https://garden.oldwinter.top/)\n- [SethMB Work](https://sethmb.xyz/)\n- [Abhijeet's Math Wiki](https://abhmul.github.io/quartz/Math-Wiki/)\n- [Mike's AI Garden 🤖🪴](https://mwalton.me/)\n\nIf you want to see your own on here, submit a [Pull Request adding yourself to this file](https://github.com/jackyzha0/quartz/blob/hugo/content/notes/showcase.md)!\n","lastmodified":"2023-07-25T13:18:04.76388289Z","tags":[]},"/notes/troubleshooting":{"title":"Troubleshooting and FAQ","content":"\nStill having trouble? Here are a list of common questions and problems people encounter when installing Quartz.\n\nWhile you're here, join our [Discord](https://discord.gg/cRFFHYye7t) :)\n\n### Does Quartz have Latex support?\nYes! See [CJK + Latex Support (测试)](notes/CJK%20+%20Latex%20Support%20(测试).md) for a brief demo.\n\n### Can I use \\\u003cObsidian Plugin\\\u003e in Quartz?\nUnless it produces direct Markdown output in the file, no. There currently is no way to bundle plugin code with Quartz.\n\nThe easiest way would be to add your own HTML partial that supports the functionality you are looking for.\n\n### My GitHub pages is just showing the README and not Quartz\nMake sure you set the source to deploy from `master` (and not `hugo`) using `/ (root)`! See more in the [hosting](/notes/hosting) guide\n\n### Some of my pages have 'January 1, 0001' as the last modified date\nThis is a problem caused by `git` treating files as case-insensitive by default and some of your posts probably have capitalized file names. You can turn this off in your Quartz by running this command.\n\n```shell\n# in the root of your Quartz (same folder as config.toml)\ngit config core.ignorecase true\n\n# or globally (not recommended)\ngit config --global core.ignorecase true\n```\n\n### Can I publish only a subset of my pages?\nYes! Quartz makes selective publishing really easy. Heres a guide on [excluding pages from being published](notes/ignore%20notes.md).\n\n### Can I host this myself and not on GitHub Pages?\nYes! All built files can be found under `/public` in the `master` branch. More details under [hosting](notes/hosting.md).\n\n### `command not found: hugo-obsidian`\nMake sure you set your `GOPATH` correctly! This will allow your terminal to correctly recognize `hugo-obsidian` as an executable.\n\n```shell\n# Add the following 2 lines to your ~/.bash_profile (~/.zshrc if you are on Mac)\nexport GOPATH=/Users/$USER/go\nexport PATH=$GOPATH/bin:$PATH\n\n# In your current terminal, to reload the session\nsource ~/.bash_profile # again, (~/.zshrc if you are on Mac)\n```\n\n### How come my notes aren't being rendered?\nYou probably forgot to include front matter in your Markdown files. You can either setup [Obsidian](notes/obsidian.md) to do this for you or you need to manually define it. More details in [the 'how to edit' guide](notes/editing.md).\n\n### My custom domain isn't working!\nWalk through the steps in [the hosting guide](notes/hosting.md) again. Make sure you wait 30 min to 1 hour for changes to take effect.\n\n### How do I setup analytics?\nQuartz by default uses [Plausible](https://plausible.io/) for analytics. \n\nIf you would prefer to use Google Analytics, you can follow this [guide in the Hugo documentation](https://gohugo.io/templates/internal/#google-analytics). \n\nAlternatively, you can also import your Google Analytics data into Plausible by [following this guide](https://plausible.io/docs/google-analytics-import).\n\n\n### How do I change the content on the home page?\nTo edit the main home page, open `/content/_index.md`.\n\n### How do I change the colours?\nYou can change the theme by editing `assets/custom.scss`. More details on customization and themeing can be found in the [customization guide](notes/config.md).\n\n### How do I add images?\nYou can put images anywhere in the `/content` folder.\n\n```markdown\nExample image (source is in content/notes/images/example.png)\n![Example Image](/content/notes/images/example.png)\n```\n\n### My Interactive Graph and Backlinks aren't up to date\nBy default, the `linkIndex.json` (which Quartz needs to generate the Interactive Graph and Backlinks) are not regenerated locally. To set that up, see the guide on [local editing](notes/editing.md)\n\n### Can I use React/Vue/some other framework?\nNot out of the box. You could probably make it work by editing `/layouts/_default/single.html` but that's not what Quartz is designed to work with. 99% of things you are trying to do with those frameworks you can accomplish perfectly fine using just vanilla HTML/CSS/JS.\n\n## Still Stuck?\nQuartz isn't perfect! If you're still having troubles, file an issue in the GitHub repo with as much information as you can reasonably provide. Alternatively, you can message me on [Twitter](https://twitter.com/_jzhao) and I'll try to get back to you as soon as I can.\n\n🐛 [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n","lastmodified":"2023-07-25T13:18:04.76388289Z","tags":[]},"/notes/updating":{"title":"Updating","content":"\nHaven't updated Quartz in a while and want all the cool new optimizations? On Unix/Mac systems you can run the following command for a one-line update! This command will show you a log summary of all commits since you last updated, press `q` to acknowledge this. Then, it will show you each change in turn and press `y` to accept the patch or `n` to reject it. Usually you should press `y` for most of these unless it conflicts with existing changes you've made! \n\n```shell\nmake update\n```\n\nOr, if you don't want the interactive parts and just want to force update your local garden (this assumed that you are okay with some of your personalizations been overriden!)\n\n```shell\nmake update-force\n```\n\nOr, manually checkout the changes yourself.\n\n\u003e [!warning] Warning!\n\u003e\n\u003e If you customized the files in `data/`, or anything inside `layouts/`, your customization may be overwritten!\n\u003e Make sure you have a copy of these changes if you don't want to lose them.\n\n\n```shell\n# add Quartz as a remote host\ngit remote add upstream git@github.com:jackyzha0/quartz.git\n\n# index and fetch changes\ngit fetch upstream\ngit checkout -p upstream/hugo -- layouts .github Makefile assets/js assets/styles/base.scss assets/styles/darkmode.scss config.toml data \n```\n","lastmodified":"2023-07-25T13:18:04.76388289Z","tags":[]}}